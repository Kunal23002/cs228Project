{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2-EYrzhyA_1"
      },
      "source": [
        "# ASR Attacks with Codec Compression Testing\n",
        "\n",
        "## Overview\n",
        "This notebook implements two ASR attacks (Carlini & Wagner and Qin) with codec compression testing.\n",
        "\n",
        "## Workflow\n",
        "For each attack:\n",
        "1. Generate adversarial audio → compute metrics (WER, CER, SNR, PESQ, STOI)\n",
        "2. Compress to OPUS → transcribe → compute metrics\n",
        "3. Compress to AMR-WB → transcribe → compute metrics\n",
        "\n",
        "## Configuration\n",
        "- **c_weight**: 1e-2 (maintains good audio quality)\n",
        "- **OPUS bitrate**: 64 kbps\n",
        "- **AMR-WB bitrate**: 23.85 kbps\n",
        "\n",
        "## Output Files\n",
        "- `adv_cw.wav` - Carlini & Wagner adversarial\n",
        "- `adv_cw_opus.wav` - C&W compressed with OPUS\n",
        "- `adv_cw_amrwb.wav` - C&W compressed with AMR-WB\n",
        "- `adv_qin.wav` - Qin adversarial\n",
        "- `adv_qin_opus.wav` - Qin compressed with OPUS\n",
        "- `adv_qin_amrwb.wav` - Qin compressed with AMR-WB\n",
        "- `results_{filename}_{timestamp}.json` - All metrics and results\n",
        "\n",
        "## Important Notes:\n",
        "- Update `AUDIO_FILE_PATH` in cell 6 to point to your audio file\n",
        "- All results are saved to JSON for analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7PGo7wbylIG"
      },
      "source": [
        "Carlini & Wagner (2018) - Targeted Attack on Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Casj-kyHWc",
        "outputId": "3ad177ee-6e8f-49bf-8bbc-7088c0d5a83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uO8YJpQzyH1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9ae287cd-ea01-479f-d765-debbda247d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r                                                                               \rHit:3 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,157 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,498 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,839 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Fetched 37.5 MB in 3s (11.7 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libaribb24-0 libavcodec-extra58 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libvo-amrwbenc0\n",
            "Suggested packages:\n",
            "  libcuda1 libnvcuvid1 libnvidia-encode1\n",
            "The following packages will be REMOVED:\n",
            "  libavcodec58\n",
            "The following NEW packages will be installed:\n",
            "  libaribb24-0 libavcodec-extra libavcodec-extra58 libopencore-amrnb0\n",
            "  libopencore-amrwb0 libvo-amrwbenc0\n",
            "0 upgraded, 6 newly installed, 1 to remove and 58 not upgraded.\n",
            "Need to get 5,821 kB of archives.\n",
            "After this operation, 590 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaribb24-0 amd64 1.0.3-2 [26.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvo-amrwbenc0 amd64 0.1.3-2 [68.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libavcodec-extra58 amd64 7:4.4.2-0ubuntu0.22.04.1 [5,566 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libavcodec-extra amd64 7:4.4.2-0ubuntu0.22.04.1 [15.2 kB]\n",
            "Fetched 5,821 kB in 2s (3,563 kB/s)\n",
            "Selecting previously unselected package libaribb24-0:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libaribb24-0_1.0.3-2_amd64.deb ...\n",
            "Unpacking libaribb24-0:amd64 (1.0.3-2) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libvo-amrwbenc0:amd64.\n",
            "Preparing to unpack .../libvo-amrwbenc0_0.1.3-2_amd64.deb ...\n",
            "Unpacking libvo-amrwbenc0:amd64 (0.1.3-2) ...\n",
            "dpkg: libavcodec58:amd64: dependency problems, but removing anyway as you requested:\n",
            " libchromaprint1:amd64 depends on libavcodec58 (>= 7:4.4).\n",
            " libavformat58:amd64 depends on libavcodec58 (= 7:4.4.2-0ubuntu0.22.04.1).\n",
            " libavfilter7:amd64 depends on libavcodec58 (= 7:4.4.2-0ubuntu0.22.04.1).\n",
            " libavdevice58:amd64 depends on libavcodec58 (= 7:4.4.2-0ubuntu0.22.04.1).\n",
            " ffmpeg depends on libavcodec58 (= 7:4.4.2-0ubuntu0.22.04.1).\n",
            "\n",
            "(Reading database ... 121737 files and directories currently installed.)\n",
            "Removing libavcodec58:amd64 (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libavcodec-extra58:amd64.\n",
            "(Reading database ... 121731 files and directories currently installed.)\n",
            "Preparing to unpack .../libavcodec-extra58_7%3a4.4.2-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libavcodec-extra58:amd64 (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libavcodec-extra:amd64.\n",
            "Preparing to unpack .../libavcodec-extra_7%3a4.4.2-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libavcodec-extra:amd64 (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Setting up libvo-amrwbenc0:amd64 (0.1.3-2) ...\n",
            "Setting up libaribb24-0:amd64 (1.0.3-2) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libavcodec-extra58:amd64 (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Setting up libavcodec-extra:amd64 (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y ffmpeg libavcodec-extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s490JZm1t0Tx",
        "outputId": "e502c654-b6f9-48ad-9eb0-96d5e8d7beba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!apt install ffmpeg -y\n",
        "\n",
        "!pip install openai-whisper librosa soundfile pesq pystoi --quiet\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import IPython.display as ipd\n",
        "from pesq import pesq\n",
        "from pystoi import stoi\n",
        "\n",
        "# For reproducibility\n",
        "torch.random.manual_seed(0)\n",
        "np.random.seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVXFX6wruzrV",
        "outputId": "629f1667-8563-4ef1-fa46-6178c6bdba4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 120MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")  # Load Whisper ASR model (English)\n",
        "print(\"Whisper model loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgiJWk4au6mZ",
        "outputId": "0dcfa54c-2145-40f9-97a6-a45f3f2a6369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded audio from: /content/drive/MyDrive/adversarial-audio/Normal-Examples/long-signals/sample-070236.wav\n",
            "Saved original.wav with sampling rate 16000 Hz and length 6.60 seconds.\n"
          ]
        }
      ],
      "source": [
        "# Load audio from drive path\n",
        "# UPDATE THIS PATH to your audio file location\n",
        "AUDIO_FILE_PATH = \"/content/drive/MyDrive/adversarial-audio/Normal-Examples/long-signals/sample-070236.wav\"  # Change this to your path\n",
        "\n",
        "# Load and resample to 16000 Hz (Whisper expects 16k audio)\n",
        "audio, sr = librosa.load(AUDIO_FILE_PATH, sr=16000)\n",
        "sf.write(\"original.wav\", audio, 16000)\n",
        "print(f\"Loaded audio from: {AUDIO_FILE_PATH}\")\n",
        "print(f\"Saved original.wav with sampling rate {16000} Hz and length {audio.shape[0]/16000:.2f} seconds.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otQFMYKsv4EV",
        "outputId": "8bf888b2-c27d-4742-c224-526e2c5681c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Transcription: We are part of that soul, so we really recognize that it is working for us.\n"
          ]
        }
      ],
      "source": [
        "# Transcribe the original audio using our ASR model\n",
        "result_orig = model.transcribe(\"original.wav\")\n",
        "print(\"Original Transcription:\", result_orig[\"text\"].strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmWCE2gk_2wm",
        "outputId": "f37ad777-7743-44e3-f497-83d1cf32ac6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded!\n"
          ]
        }
      ],
      "source": [
        "# Helper Functions for Codec Compression and Metrics\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def compress_audio_codec(audio_path, codec_name, bitrate, output_path, sr=16000):\n",
        "    \"\"\"\n",
        "    Compress audio using OPUS or AMR-WB codec and decode back to WAV.\n",
        "\n",
        "    Args:\n",
        "        audio_path: Path to input WAV file\n",
        "        codec_name: 'opus' or 'amr-wb'\n",
        "        bitrate: Bitrate in kbps\n",
        "        output_path: Path for output WAV file (decoded)\n",
        "        sr: Sample rate (default 16000)\n",
        "\n",
        "    Returns:\n",
        "        Path to decoded WAV file if successful, None otherwise\n",
        "    \"\"\"\n",
        "    codec_map = {\n",
        "        'opus': {'codec': 'libopus', 'ext': '.opus'},\n",
        "        'amr-wb': {'codec': 'libvo_amrwbenc', 'ext': '.amr'}\n",
        "    }\n",
        "\n",
        "    if codec_name not in codec_map:\n",
        "        print(f\"Unknown codec: {codec_name}\")\n",
        "        return None\n",
        "\n",
        "    codec_info = codec_map[codec_name]\n",
        "    encoded_path = str(output_path).replace('.wav', codec_info['ext'])\n",
        "\n",
        "    try:\n",
        "        # Encode\n",
        "        encode_cmd = [\n",
        "            'ffmpeg', '-y', '-i', str(audio_path),\n",
        "            '-acodec', codec_info['codec'],\n",
        "            '-b:a', f'{bitrate}k',\n",
        "            '-ar', str(sr),\n",
        "            '-ac', '1',\n",
        "            encoded_path\n",
        "        ]\n",
        "        subprocess.run(encode_cmd, capture_output=True, check=True)\n",
        "\n",
        "        # Decode back to WAV\n",
        "        decode_cmd = [\n",
        "            'ffmpeg', '-y', '-i', encoded_path,\n",
        "            '-acodec', 'pcm_s16le',\n",
        "            '-ar', str(sr),\n",
        "            '-ac', '1',\n",
        "            str(output_path)\n",
        "        ]\n",
        "        subprocess.run(decode_cmd, capture_output=True, check=True)\n",
        "\n",
        "        return Path(output_path)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Codec compression failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def compute_wer(reference: str, hypothesis: str) -> float:\n",
        "    \"\"\"Compute Word Error Rate (WER).\"\"\"\n",
        "    ref_words = reference.lower().split()\n",
        "    hyp_words = hypothesis.lower().split()\n",
        "\n",
        "    if len(ref_words) == 0:\n",
        "        return 1.0 if len(hyp_words) > 0 else 0.0\n",
        "\n",
        "    d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1))\n",
        "    for i in range(len(ref_words) + 1):\n",
        "        d[i, 0] = i\n",
        "    for j in range(len(hyp_words) + 1):\n",
        "        d[0, j] = j\n",
        "\n",
        "    for i in range(1, len(ref_words) + 1):\n",
        "        for j in range(1, len(hyp_words) + 1):\n",
        "            if ref_words[i-1] == hyp_words[j-1]:\n",
        "                d[i, j] = d[i-1, j-1]\n",
        "            else:\n",
        "                d[i, j] = min(d[i-1, j] + 1, d[i, j-1] + 1, d[i-1, j-1] + 1)\n",
        "\n",
        "    return d[len(ref_words), len(hyp_words)] / len(ref_words)\n",
        "\n",
        "def compute_cer(reference: str, hypothesis: str) -> float:\n",
        "    \"\"\"Compute Character Error Rate (CER).\"\"\"\n",
        "    ref_chars = list(reference.lower().replace(\" \", \"\"))\n",
        "    hyp_chars = list(hypothesis.lower().replace(\" \", \"\"))\n",
        "\n",
        "    if len(ref_chars) == 0:\n",
        "        return 1.0 if len(hyp_chars) > 0 else 0.0\n",
        "\n",
        "    d = np.zeros((len(ref_chars) + 1, len(hyp_chars) + 1))\n",
        "    for i in range(len(ref_chars) + 1):\n",
        "        d[i, 0] = i\n",
        "    for j in range(len(hyp_chars) + 1):\n",
        "        d[0, j] = j\n",
        "\n",
        "    for i in range(1, len(ref_chars) + 1):\n",
        "        for j in range(1, len(hyp_chars) + 1):\n",
        "            if ref_chars[i-1] == hyp_chars[j-1]:\n",
        "                d[i, j] = d[i-1, j-1]\n",
        "            else:\n",
        "                d[i, j] = min(d[i-1, j] + 1, d[i, j-1] + 1, d[i-1, j-1] + 1)\n",
        "\n",
        "    return d[len(ref_chars), len(hyp_chars)] / len(ref_chars)\n",
        "\n",
        "def compute_all_metrics(original_audio_path, processed_audio_path, original_transcript, processed_transcript, sr=16000):\n",
        "    \"\"\"\n",
        "    Compute all metrics: WER, CER, SNR, PESQ, STOI.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with all metrics\n",
        "    \"\"\"\n",
        "    # Load audio\n",
        "    orig_audio, _ = librosa.load(original_audio_path, sr=sr)\n",
        "    proc_audio, _ = librosa.load(processed_audio_path, sr=sr)\n",
        "\n",
        "    # Ensure same length\n",
        "    min_len = min(len(orig_audio), len(proc_audio))\n",
        "    orig_audio = orig_audio[:min_len]\n",
        "    proc_audio = proc_audio[:min_len]\n",
        "\n",
        "    # Compute WER and CER\n",
        "    wer = compute_wer(original_transcript, processed_transcript)\n",
        "    cer = compute_cer(original_transcript, processed_transcript)\n",
        "\n",
        "    # Calculate SNR\n",
        "    signal_power = np.mean(orig_audio ** 2)\n",
        "    noise_power = np.mean((proc_audio - orig_audio) ** 2)\n",
        "    snr_db = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')\n",
        "\n",
        "    # Calculate PESQ\n",
        "    try:\n",
        "        pesq_score = pesq(sr, orig_audio, proc_audio, 'wb')\n",
        "    except:\n",
        "        pesq_score = 0.0\n",
        "\n",
        "    # Calculate STOI\n",
        "    try:\n",
        "        stoi_score = stoi(orig_audio, proc_audio, sr, extended=False)\n",
        "    except:\n",
        "        stoi_score = 0.0\n",
        "\n",
        "    return {\n",
        "        'wer': float(wer),\n",
        "        'cer': float(cer),\n",
        "        'snr': float(snr_db) if snr_db != float('inf') else None,\n",
        "        'pesq': float(pesq_score),\n",
        "        'stoi': float(stoi_score)\n",
        "    }\n",
        "\n",
        "print(\"Helper functions loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxwNE043v670",
        "outputId": "1a99c4de-1a29-4c18-b688-53a75f3d91d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Transcription (attack goal): We are cart of that coal, so we really recognize that it is working for us.\n"
          ]
        }
      ],
      "source": [
        "target_phrase = \"We are cart of that coal, so we really recognize that it is working for us.\"\n",
        "print(\"Target Transcription (attack goal):\", target_phrase)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WULAWtQFwIsE",
        "outputId": "889b8540-be88-4850-e15d-a6528e73d2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: ASR loss=6.8088, distortion=0.000000, total=6.8088\n",
            "Iter 50: ASR loss=0.7935, distortion=0.000151, total=0.7935\n",
            "Iter 100: ASR loss=0.1348, distortion=0.000189, total=0.1348\n",
            "Iter 150: ASR loss=0.0277, distortion=0.000198, total=0.0277\n",
            "Iter 199: ASR loss=0.0159, distortion=0.000199, total=0.0159\n",
            "\n",
            "Adversarial audio saved to adv_cw.wav\n",
            "Perturbation stats: max=0.078460, mean=0.011662\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Targeted Carlini & Wagner-style attack optimized directly on Whisper\n",
        "# (gradient-based search that trades off ASR target loss and small perturbation)\n",
        "\n",
        "# Prepare tokens for the target phrase\n",
        "device = next(model.parameters()).device\n",
        "try:\n",
        "    tokenizer = whisper.tokenizer.get_tokenizer(multilingual=model.is_multilingual, language=\"en\", task=\"transcribe\")\n",
        "except Exception:\n",
        "    tokenizer = whisper.tokenizer.get_tokenizer(multilingual=False, language=\"en\", task=\"transcribe\")\n",
        "\n",
        "target_token_ids = [tokenizer.sot] + tokenizer.encode(target_phrase) + [tokenizer.eot]\n",
        "target_tokens = torch.tensor(target_token_ids, dtype=torch.long, device=device)\n",
        "\n",
        "# Load audio and create trainable perturbation (ensure mono 1D)\n",
        "audio_np, sr = sf.read(\"original.wav\")\n",
        "if audio_np.ndim > 1:\n",
        "    audio_np = audio_np.mean(axis=1)\n",
        "orig_audio = torch.tensor(audio_np, dtype=torch.float32, device=device)\n",
        "delta = torch.zeros_like(orig_audio, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([delta], lr=2e-3)\n",
        "c_weight = 1e-2  # Updated to maintain good quality of sound\n",
        "num_iterations = 200\n",
        "\n",
        "# FIXED: Don't detach audio - keep gradients flowing\n",
        "def whisper_targeted_loss(audio_wave: torch.Tensor, tokens: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Cross-entropy between Whisper logits and target tokens (teacher forcing).\"\"\"\n",
        "    # Keep audio on device and don't detach - this is critical for gradients!\n",
        "    audio_for_mel = whisper.pad_or_trim(audio_wave.cpu())  # Only move to CPU for processing, not detach\n",
        "    mel = whisper.log_mel_spectrogram(audio_for_mel).unsqueeze(0).to(device)\n",
        "    tokens_in = tokens[:-1].unsqueeze(0)\n",
        "    targets = tokens[1:].unsqueeze(0)\n",
        "\n",
        "    # Enable gradients for the model\n",
        "    model.train()  # Enable training mode for gradients\n",
        "    logits = model(mel, tokens_in)\n",
        "    logits = logits[:, -targets.shape[1]:, :]\n",
        "    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "    return loss\n",
        "\n",
        "# Set model to eval mode but enable gradients\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  # Don't update model weights, only the perturbation\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    optimizer.zero_grad()\n",
        "    adv_wave = torch.clamp(orig_audio + delta, -1.0, 1.0)\n",
        "    loss_asr = whisper_targeted_loss(adv_wave, target_tokens)\n",
        "    distortion = torch.mean((adv_wave - orig_audio) ** 2)\n",
        "    loss = loss_asr + c_weight * distortion\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if iteration % 50 == 0 or iteration == num_iterations - 1:\n",
        "        print(f\"Iter {iteration}: ASR loss={loss_asr.item():.4f}, distortion={distortion.item():.6f}, total={loss.item():.4f}\")\n",
        "\n",
        "# Save the adversarial example\n",
        "adv_audio = torch.clamp(orig_audio + delta, -1.0, 1.0).detach().cpu().numpy()\n",
        "sf.write(\"adv_cw.wav\", adv_audio, sr)\n",
        "print(f\"\\nAdversarial audio saved to adv_cw.wav\")\n",
        "print(f\"Perturbation stats: max={np.max(np.abs(adv_audio - audio_np)):.6f}, mean={np.mean(np.abs(adv_audio - audio_np)):.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZRuFqA4wl4f",
        "outputId": "4e1a175e-ace5-4824-9f55-42952f9823c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CARLINI & WAGNER ATTACK - Adversarial Audio\n",
            "================================================================================\n",
            "Original Transcription:  We are part of that soul, so we really recognize that it is working for us.\n",
            "Adversarial Transcription: We are cart of that coal so we really recognize that it is working for us.\n",
            "Metrics (Original vs Adversarial):\n",
            "  WER: 0.1250 (12.50%)\n",
            "  CER: 0.0667 (6.67%)\n",
            "  SNR: 6.66 dB\n",
            "  PESQ: 1.1582\n",
            "  STOI: 0.5700\n",
            "================================================================================\n",
            "CARLINI & WAGNER ATTACK - OPUS Compression\n",
            "================================================================================\n",
            "OPUS Compressed Transcription: We are caught of that coal so we really recognize that it is working for us.\n",
            "Metrics (Original vs OPUS Compressed):\n",
            "  WER: 0.1250 (12.50%)\n",
            "  CER: 0.1167 (11.67%)\n",
            "  SNR: 6.92 dB\n",
            "  PESQ: 1.1687\n",
            "  STOI: 0.5696\n",
            "================================================================================\n",
            "CARLINI & WAGNER ATTACK - AMR-WB Compression\n",
            "================================================================================\n",
            "AMR-WB Compressed Transcription: We are caught of that soul, so we really recognize that it is working for us.\n",
            "Metrics (Original vs AMR-WB Compressed):\n",
            "  WER: 0.0625 (6.25%)\n",
            "  CER: 0.0667 (6.67%)\n",
            "  SNR: -1.75 dB\n",
            "  PESQ: 1.2123\n",
            "  STOI: 0.5072\n"
          ]
        }
      ],
      "source": [
        "# Initialize results dictionary\n",
        "original_transcript = result_orig[\"text\"].strip()\n",
        "results = {\n",
        "    \"audio_file\": AUDIO_FILE_PATH,\n",
        "    \"original_transcript\": original_transcript,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"attacks\": {\n",
        "        \"carlini_wagner\": {},\n",
        "        \"qin\": {}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Carlini & Wagner Attack - Adversarial Audio Metrics\n",
        "print(\"=\"*80)\n",
        "print(\"CARLINI & WAGNER ATTACK - Adversarial Audio\")\n",
        "print(\"=\"*80)\n",
        "result_adv_cw = model.transcribe(\"adv_cw.wav\")\n",
        "adv_cw_transcript = result_adv_cw[\"text\"].strip()\n",
        "print(f\"Original Transcription:  {original_transcript}\")\n",
        "print(f\"Adversarial Transcription: {adv_cw_transcript}\")\n",
        "\n",
        "# Compute metrics on adversarial audio\n",
        "metrics_adv = compute_all_metrics(\"original.wav\", \"adv_cw.wav\", original_transcript, adv_cw_transcript)\n",
        "results[\"attacks\"][\"carlini_wagner\"][\"adversarial\"] = {\n",
        "    \"file\": \"adv_cw.wav\",\n",
        "    \"transcript\": adv_cw_transcript,\n",
        "    \"metrics\": metrics_adv\n",
        "}\n",
        "\n",
        "print(\"Metrics (Original vs Adversarial):\")\n",
        "print(f\"  WER: {metrics_adv['wer']:.4f} ({metrics_adv['wer']*100:.2f}%)\")\n",
        "print(f\"  CER: {metrics_adv['cer']:.4f} ({metrics_adv['cer']*100:.2f}%)\")\n",
        "print(f\"  SNR: {metrics_adv['snr']:.2f} dB\" if metrics_adv['snr'] else f\"  SNR: inf dB\")\n",
        "print(f\"  PESQ: {metrics_adv['pesq']:.4f}\")\n",
        "print(f\"  STOI: {metrics_adv['stoi']:.4f}\")\n",
        "\n",
        "# Path 1: Compress to OPUS\n",
        "print(\"\" + \"=\"*80)\n",
        "print(\"CARLINI & WAGNER ATTACK - OPUS Compression\")\n",
        "print(\"=\"*80)\n",
        "opus_path = compress_audio_codec(\"adv_cw.wav\", \"opus\", 64, \"adv_cw_opus.wav\")\n",
        "if opus_path and opus_path.exists():\n",
        "    result_opus = model.transcribe(str(opus_path))\n",
        "    opus_transcript = result_opus[\"text\"].strip()\n",
        "    print(f\"OPUS Compressed Transcription: {opus_transcript}\")\n",
        "\n",
        "    metrics_opus = compute_all_metrics(\"original.wav\", str(opus_path), original_transcript, opus_transcript)\n",
        "    results[\"attacks\"][\"carlini_wagner\"][\"opus\"] = {\n",
        "        \"file\": \"adv_cw_opus.wav\",\n",
        "        \"transcript\": opus_transcript,\n",
        "        \"metrics\": metrics_opus\n",
        "    }\n",
        "\n",
        "    print(\"Metrics (Original vs OPUS Compressed):\")\n",
        "    print(f\"  WER: {metrics_opus['wer']:.4f} ({metrics_opus['wer']*100:.2f}%)\")\n",
        "    print(f\"  CER: {metrics_opus['cer']:.4f} ({metrics_opus['cer']*100:.2f}%)\")\n",
        "    print(f\"  SNR: {metrics_opus['snr']:.2f} dB\" if metrics_opus['snr'] else f\"  SNR: inf dB\")\n",
        "    print(f\"  PESQ: {metrics_opus['pesq']:.4f}\")\n",
        "    print(f\"  STOI: {metrics_opus['stoi']:.4f}\")\n",
        "else:\n",
        "    print(\"OPUS compression failed!\")\n",
        "    results[\"attacks\"][\"carlini_wagner\"][\"opus\"] = {\"error\": \"Compression failed\"}\n",
        "\n",
        "# Path 2: Compress to AMR-WB\n",
        "print(\"\" + \"=\"*80)\n",
        "print(\"CARLINI & WAGNER ATTACK - AMR-WB Compression\")\n",
        "print(\"=\"*80)\n",
        "amrwb_path = compress_audio_codec(\"adv_cw.wav\", \"amr-wb\", 23.85, \"adv_cw_amrwb.wav\")\n",
        "if amrwb_path and amrwb_path.exists():\n",
        "    result_amrwb = model.transcribe(str(amrwb_path))\n",
        "    amrwb_transcript = result_amrwb[\"text\"].strip()\n",
        "    print(f\"AMR-WB Compressed Transcription: {amrwb_transcript}\")\n",
        "\n",
        "    metrics_amrwb = compute_all_metrics(\"original.wav\", str(amrwb_path), original_transcript, amrwb_transcript)\n",
        "    results[\"attacks\"][\"carlini_wagner\"][\"amr_wb\"] = {\n",
        "        \"file\": \"adv_cw_amrwb.wav\",\n",
        "        \"transcript\": amrwb_transcript,\n",
        "        \"metrics\": metrics_amrwb\n",
        "    }\n",
        "\n",
        "    print(\"Metrics (Original vs AMR-WB Compressed):\")\n",
        "    print(f\"  WER: {metrics_amrwb['wer']:.4f} ({metrics_amrwb['wer']*100:.2f}%)\")\n",
        "    print(f\"  CER: {metrics_amrwb['cer']:.4f} ({metrics_amrwb['cer']*100:.2f}%)\")\n",
        "    print(f\"  SNR: {metrics_amrwb['snr']:.2f} dB\" if metrics_amrwb['snr'] else f\"  SNR: inf dB\")\n",
        "    print(f\"  PESQ: {metrics_amrwb['pesq']:.4f}\")\n",
        "    print(f\"  STOI: {metrics_amrwb['stoi']:.4f}\")\n",
        "else:\n",
        "    print(\"AMR-WB compression failed!\")\n",
        "    results[\"attacks\"][\"carlini_wagner\"][\"amr_wb\"] = {\"error\": \"Compression failed\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_4Q1SPqytat"
      },
      "source": [
        "Imperceptible Adversarial Examples (Qin et al., 2019) - Psychoacoustic Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n29WGIKE1SfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79cd57a2-6f8a-4a75-f85c-af66582cf2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: ASR loss=6.8088, distortion=0.000000, total=6.8088\n",
            "Iter 50: ASR loss=0.8822, distortion=0.000151, total=0.8822\n",
            "Iter 100: ASR loss=0.2035, distortion=0.000194, total=0.2035\n",
            "Iter 150: ASR loss=0.0299, distortion=0.000208, total=0.0299\n",
            "Iter 200: ASR loss=0.0165, distortion=0.000209, total=0.0165\n",
            "Iter 250: ASR loss=0.0120, distortion=0.000210, total=0.0120\n",
            "Iter 300: ASR loss=0.0088, distortion=0.000211, total=0.0088\n",
            "Iter 350: ASR loss=0.0071, distortion=0.000211, total=0.0071\n",
            "Iter 399: ASR loss=0.0057, distortion=0.000212, total=0.0057\n",
            "\n",
            "✓ Adversarial audio saved to adv_qin.wav (size: 211244 bytes)\n",
            "Perturbation stats: max=0.092357, mean=0.011918\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Targeted Carlini & Wagner-style attack optimized directly on Whisper\n",
        "# (gradient-based search that trades off ASR target loss and small perturbation)\n",
        "\n",
        "# Prepare tokens for the target phrase\n",
        "device = next(model.parameters()).device\n",
        "try:\n",
        "    tokenizer = whisper.tokenizer.get_tokenizer(multilingual=model.is_multilingual, language=\"en\", task=\"transcribe\")\n",
        "except Exception:\n",
        "    tokenizer = whisper.tokenizer.get_tokenizer(multilingual=False, language=\"en\", task=\"transcribe\")\n",
        "\n",
        "target_token_ids = [tokenizer.sot] + tokenizer.encode(target_phrase) + [tokenizer.eot]\n",
        "target_tokens = torch.tensor(target_token_ids, dtype=torch.long, device=device)\n",
        "\n",
        "# Load audio and create trainable perturbation (ensure mono 1D)\n",
        "audio_np, sr = sf.read(\"original.wav\")\n",
        "if audio_np.ndim > 1:\n",
        "    audio_np = audio_np.mean(axis=1)\n",
        "orig_audio = torch.tensor(audio_np, dtype=torch.float32, device=device)\n",
        "delta = torch.zeros_like(orig_audio, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([delta], lr=2e-3)\n",
        "c_weight = 1e-2  # Updated to maintain good quality of sound\n",
        "num_iterations = 400\n",
        "\n",
        "# FIXED: Don't detach audio - keep gradients flowing\n",
        "def whisper_targeted_loss(audio_wave: torch.Tensor, tokens: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Cross-entropy between Whisper logits and target tokens (teacher forcing).\"\"\"\n",
        "    # Keep audio on device and don't detach - this is critical for gradients!\n",
        "    audio_for_mel = whisper.pad_or_trim(audio_wave.cpu())  # Only move to CPU for processing, not detach\n",
        "    mel = whisper.log_mel_spectrogram(audio_for_mel).unsqueeze(0).to(device)\n",
        "    tokens_in = tokens[:-1].unsqueeze(0)\n",
        "    targets = tokens[1:].unsqueeze(0)\n",
        "\n",
        "    # Enable gradients for the model\n",
        "    model.train()  # Enable training mode for gradients\n",
        "    logits = model(mel, tokens_in)\n",
        "    logits = logits[:, -targets.shape[1]:, :]\n",
        "    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "    return loss\n",
        "\n",
        "# Set model to eval mode but enable gradients\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  # Don't update model weights, only the perturbation\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    optimizer.zero_grad()\n",
        "    adv_wave = torch.clamp(orig_audio + delta, -1.0, 1.0)\n",
        "    loss_asr = whisper_targeted_loss(adv_wave, target_tokens)\n",
        "    distortion = torch.mean((adv_wave - orig_audio) ** 2)\n",
        "    loss = loss_asr + c_weight * distortion\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if iteration % 50 == 0 or iteration == num_iterations - 1:\n",
        "        print(f\"Iter {iteration}: ASR loss={loss_asr.item():.4f}, distortion={distortion.item():.6f}, total={loss.item():.4f}\")\n",
        "\n",
        "# Save the adversarial example\n",
        "adv_audio = torch.clamp(orig_audio + delta, -1.0, 1.0).detach().cpu().numpy()\n",
        "try:\n",
        "    sf.write(\"adv_qin.wav\", adv_audio, sr)\n",
        "    # Verify file was saved\n",
        "    import os\n",
        "    if os.path.exists(\"adv_qin.wav\"):\n",
        "        file_size = os.path.getsize(\"adv_qin.wav\")\n",
        "        print(f\"\\n✓ Adversarial audio saved to adv_qin.wav (size: {file_size} bytes)\")\n",
        "        print(f\"Perturbation stats: max={np.max(np.abs(adv_audio - audio_np)):.6f}, mean={np.mean(np.abs(adv_audio - audio_np)):.6f}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ WARNING: File adv_qin.wav was not created! Attempting to save again...\")\n",
        "        # Try saving with absolute path\n",
        "        sf.write(\"/content/adv_qin.wav\", adv_audio, sr)\n",
        "        if os.path.exists(\"/content/adv_qin.wav\"):\n",
        "            print(\"✓ File saved to /content/adv_qin.wav\")\n",
        "        else:\n",
        "            print(\"✗ ERROR: Failed to save adv_qin.wav\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ ERROR saving adv_qin.wav: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Qin Attack - Adversarial Audio Metrics\n",
        "print(\"=\"*80)\n",
        "print(\"QIN ATTACK - Adversarial Audio\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check if adv_qin.wav exists, if not, the attack may have failed\n",
        "import os\n",
        "qin_file = None\n",
        "if os.path.exists(\"adv_qin.wav\"):\n",
        "    qin_file = \"adv_qin.wav\"\n",
        "elif os.path.exists(\"/content/adv_qin.wav\"):\n",
        "    qin_file = \"/content/adv_qin.wav\"\n",
        "    print(\"Found adv_qin.wav at /content/adv_qin.wav\")\n",
        "\n",
        "if qin_file is None:\n",
        "    print(\"ERROR: adv_qin.wav not found! The Qin attack may have failed.\")\n",
        "    print(\"Please check Cell 13 output to see if the attack completed successfully.\")\n",
        "    print(\"Skipping Qin attack metrics...\")\n",
        "    results[\"attacks\"][\"qin\"][\"adversarial\"] = {\"error\": \"adv_qin.wav file not found - attack may have failed\"}\n",
        "else:\n",
        "    try:\n",
        "        print(f\"Transcribing {qin_file}...\")\n",
        "        result_adv_qin = model.transcribe(qin_file)\n",
        "        adv_qin_transcript = result_adv_qin[\"text\"].strip()\n",
        "        print(f\"Original Transcription:  {original_transcript}\")\n",
        "        print(f\"Adversarial Transcription: {adv_qin_transcript}\")\n",
        "\n",
        "        # Compute metrics on adversarial audio\n",
        "        metrics_adv_qin = compute_all_metrics(\"original.wav\", qin_file, original_transcript, adv_qin_transcript)\n",
        "        results[\"attacks\"][\"qin\"][\"adversarial\"] = {\n",
        "            \"file\": \"adv_qin.wav\",\n",
        "            \"transcript\": adv_qin_transcript,\n",
        "            \"metrics\": metrics_adv_qin\n",
        "        }\n",
        "\n",
        "        print(\"\\nMetrics (Original vs Adversarial):\")\n",
        "        print(f\"  WER: {metrics_adv_qin['wer']:.4f} ({metrics_adv_qin['wer']*100:.2f}%)\")\n",
        "        print(f\"  CER: {metrics_adv_qin['cer']:.4f} ({metrics_adv_qin['cer']*100:.2f}%)\")\n",
        "        print(f\"  SNR: {metrics_adv_qin['snr']:.2f} dB\" if metrics_adv_qin['snr'] else f\"  SNR: inf dB\")\n",
        "        print(f\"  PESQ: {metrics_adv_qin['pesq']:.4f}\")\n",
        "        print(f\"  STOI: {metrics_adv_qin['stoi']:.4f}\")\n",
        "\n",
        "        # Path 1: Compress to OPUS\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"QIN ATTACK - OPUS Compression\")\n",
        "        print(\"=\"*80)\n",
        "        opus_path_qin = compress_audio_codec(qin_file, \"opus\", 64, \"adv_qin_opus.wav\")\n",
        "        if opus_path_qin and opus_path_qin.exists():\n",
        "            result_opus_qin = model.transcribe(str(opus_path_qin))\n",
        "            opus_transcript_qin = result_opus_qin[\"text\"].strip()\n",
        "            print(f\"OPUS Compressed Transcription: {opus_transcript_qin}\")\n",
        "\n",
        "            metrics_opus_qin = compute_all_metrics(\"original.wav\", str(opus_path_qin), original_transcript, opus_transcript_qin)\n",
        "            results[\"attacks\"][\"qin\"][\"opus\"] = {\n",
        "                \"file\": \"adv_qin_opus.wav\",\n",
        "                \"transcript\": opus_transcript_qin,\n",
        "                \"metrics\": metrics_opus_qin\n",
        "            }\n",
        "\n",
        "            print(\"\\nMetrics (Original vs OPUS Compressed):\")\n",
        "            print(f\"  WER: {metrics_opus_qin['wer']:.4f} ({metrics_opus_qin['wer']*100:.2f}%)\")\n",
        "            print(f\"  CER: {metrics_opus_qin['cer']:.4f} ({metrics_opus_qin['cer']*100:.2f}%)\")\n",
        "            print(f\"  SNR: {metrics_opus_qin['snr']:.2f} dB\" if metrics_opus_qin['snr'] else f\"  SNR: inf dB\")\n",
        "            print(f\"  PESQ: {metrics_opus_qin['pesq']:.4f}\")\n",
        "            print(f\"  STOI: {metrics_opus_qin['stoi']:.4f}\")\n",
        "        else:\n",
        "            print(\"OPUS compression failed!\")\n",
        "            results[\"attacks\"][\"qin\"][\"opus\"] = {\"error\": \"Compression failed\"}\n",
        "\n",
        "        # Path 2: Compress to AMR-WB\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"QIN ATTACK - AMR-WB Compression\")\n",
        "        print(\"=\"*80)\n",
        "        amrwb_path_qin = compress_audio_codec(qin_file, \"amr-wb\", 23.85, \"adv_qin_amrwb.wav\")\n",
        "        if amrwb_path_qin and amrwb_path_qin.exists():\n",
        "            result_amrwb_qin = model.transcribe(str(amrwb_path_qin))\n",
        "            amrwb_transcript_qin = result_amrwb_qin[\"text\"].strip()\n",
        "            print(f\"AMR-WB Compressed Transcription: {amrwb_transcript_qin}\")\n",
        "\n",
        "            metrics_amrwb_qin = compute_all_metrics(\"original.wav\", str(amrwb_path_qin), original_transcript, amrwb_transcript_qin)\n",
        "            results[\"attacks\"][\"qin\"][\"amr_wb\"] = {\n",
        "                \"file\": \"adv_qin_amrwb.wav\",\n",
        "                \"transcript\": amrwb_transcript_qin,\n",
        "                \"metrics\": metrics_amrwb_qin\n",
        "            }\n",
        "\n",
        "            print(\"\\nMetrics (Original vs AMR-WB Compressed):\")\n",
        "            print(f\"  WER: {metrics_amrwb_qin['wer']:.4f} ({metrics_amrwb_qin['wer']*100:.2f}%)\")\n",
        "            print(f\"  CER: {metrics_amrwb_qin['cer']:.4f} ({metrics_amrwb_qin['cer']*100:.2f}%)\")\n",
        "            print(f\"  SNR: {metrics_amrwb_qin['snr']:.2f} dB\" if metrics_amrwb_qin['snr'] else f\"  SNR: inf dB\")\n",
        "            print(f\"  PESQ: {metrics_amrwb_qin['pesq']:.4f}\")\n",
        "            print(f\"  STOI: {metrics_amrwb_qin['stoi']:.4f}\")\n",
        "        else:\n",
        "            print(\"AMR-WB compression failed!\")\n",
        "            results[\"attacks\"][\"qin\"][\"amr_wb\"] = {\"error\": \"Compression failed\"}\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR processing Qin attack: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results[\"attacks\"][\"qin\"][\"adversarial\"] = {\"error\": f\"Processing failed: {str(e)}\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQA4yGZ-D6Y8",
        "outputId": "0a3c2832-d5d1-4ef0-9f09-1c145ff89de4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QIN ATTACK - Adversarial Audio\n",
            "================================================================================\n",
            "Transcribing adv_qin.wav...\n",
            "Original Transcription:  We are part of that soul, so we really recognize that it is working for us.\n",
            "Adversarial Transcription: We are cart of that coal so we really recognize that it is working for us.\n",
            "\n",
            "Metrics (Original vs Adversarial):\n",
            "  WER: 0.1250 (12.50%)\n",
            "  CER: 0.0667 (6.67%)\n",
            "  SNR: 6.41 dB\n",
            "  PESQ: 1.1504\n",
            "  STOI: 0.5714\n",
            "\n",
            "================================================================================\n",
            "QIN ATTACK - OPUS Compression\n",
            "================================================================================\n",
            "OPUS Compressed Transcription: We are cart of that coal so we really recognize that it is working for us.\n",
            "\n",
            "Metrics (Original vs OPUS Compressed):\n",
            "  WER: 0.1250 (12.50%)\n",
            "  CER: 0.0667 (6.67%)\n",
            "  SNR: 6.65 dB\n",
            "  PESQ: 1.1601\n",
            "  STOI: 0.5699\n",
            "\n",
            "================================================================================\n",
            "QIN ATTACK - AMR-WB Compression\n",
            "================================================================================\n",
            "AMR-WB Compressed Transcription: We are caught of that soul. So we really recognize that it is working for us.\n",
            "\n",
            "Metrics (Original vs AMR-WB Compressed):\n",
            "  WER: 0.1250 (12.50%)\n",
            "  CER: 0.0833 (8.33%)\n",
            "  SNR: -1.83 dB\n",
            "  PESQ: 1.1989\n",
            "  STOI: 0.5033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnQV_-zg_2wo",
        "outputId": "c532f3f7-ccd1-4844-c02e-80f5ccd007a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Results saved to: results_sample-070236_20251202_031854.json\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Save results to JSON\n",
        "import os\n",
        "audio_basename = os.path.splitext(os.path.basename(AUDIO_FILE_PATH))[0]\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_filename = f\"results_{audio_basename}_{timestamp}.json\"\n",
        "\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Results saved to: {results_filename}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1Ey8mNmEftZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}