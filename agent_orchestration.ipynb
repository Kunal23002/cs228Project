{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Codec-Robust Adversarial Audio Generation with LLM Orchestration\n",
        "\n",
        "This notebook implements a comprehensive pipeline for developing and evaluating codec-robust adversarial audio that reliably degrades ASR (Automatic Speech Recognition) performance after lossy compression.\n",
        "\n",
        "## Methodology Overview\n",
        "\n",
        "1. **Normalize audio** (target sample rate, loudness) and define clean ASR baselines\n",
        "2. **Codec detection** and expose codec/bitrate candidates to LLM\n",
        "3. **LLM-guided strategy generation** (Gemini 3) proposes perturbation strategies\n",
        "4. **Executor** generates adversarial candidates with EoT (Expectation-over-Transformations)\n",
        "5. **Metrics computation** (WER/CER, PESQ, STOI, SNR, LUFS)\n",
        "6. **Feedback loop** returns structured summary to LLM for iteration\n",
        "7. **Ablations** and statistical analysis\n",
        "8. **Artifact saving** for reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q google-generativeai openai-whisper librosa soundfile pesq pystoi numpy scipy matplotlib seaborn pandas scikit-learn ffmpeg-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import google.generativeai as genai\n",
        "import whisper\n",
        "from pesq import pesq\n",
        "from pystoi import stoi\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Important: Set Your Gemini API Key\n",
        "\n",
        "Before running the notebook, make sure to set your Gemini API key:\n",
        "\n",
        "1. Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
        "2. Set it as an environment variable: `export GEMINI_API_KEY=\"your-key-here\"`\n",
        "3. Or update the `GEMINI_API_KEY` variable in the configuration cell below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "di"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"YOUR_API_KEY_HERE\")  # Set your API key\n",
        "DATASET_PATH = Path(\"/Users/kunal/Downloads/adversarial_dataset-A/Adversarial-Examples\")\n",
        "OUTPUT_DIR = Path(\"./agent_orchestration_outputs\")\n",
        "ARTIFACTS_DIR = OUTPUT_DIR / \"artifacts\"\n",
        "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
        "\n",
        "# Create output directories\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Audio processing parameters\n",
        "TARGET_SR = 16000\n",
        "NORMALIZE_PEAK = 0.99\n",
        "TARGET_LUFS = -23.0  # Broadcast standard\n",
        "\n",
        "# Codec configuration\n",
        "CODECS = {\n",
        "    \"mp3\": {\"codec\": \"libmp3lame\", \"bitrates\": [64, 128, 192, 256]},\n",
        "    \"aac\": {\"codec\": \"aac\", \"bitrates\": [64, 128, 192, 256]},\n",
        "    \"opus\": {\"codec\": \"libopus\", \"bitrates\": [32, 64, 96, 128]},\n",
        "    \"amr-wb\": {\"codec\": \"libopencore_amrwb\", \"bitrates\": [6.6, 8.85, 12.65, 14.25, 15.85, 18.25, 19.85, 23.05, 23.85]},\n",
        "    \"g711\": {\"codec\": \"pcm_mulaw\", \"bitrates\": [64]}  # Fixed bitrate\n",
        "}\n",
        "\n",
        "# ASR model\n",
        "ASR_MODEL_NAME = \"base\"  # Options: tiny, base, small, medium, large\n",
        "\n",
        "# EoT (Expectation over Transformations) parameters\n",
        "EOT_NUM_SAMPLES = 10  # Number of codec transformations per optimization step\n",
        "EOT_CHAIN_LENGTH = 3  # Maximum transcoding chain length\n",
        "\n",
        "# Perturbation constraints\n",
        "MAX_LINF = 0.01  # Maximum L∞ norm\n",
        "MAX_L2 = 0.1    # Maximum L2 norm\n",
        "MIN_PESQ = 3.0  # Minimum PESQ score\n",
        "MIN_STOI = 0.7  # Minimum STOI score\n",
        "MIN_SNR = 10.0  # Minimum SNR in dB\n",
        "TARGET_SNR = 20.0  # Target SNR in dB\n",
        "\n",
        "# LLM parameters\n",
        "MAX_ITERATIONS = 5  # Maximum feedback loop iterations\n",
        "STRATEGY_TOP_K = 3  # Top-k strategies to return to LLM\n",
        "\n",
        "print(\"Configuration loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AudioNormalizer:\n",
        "    \"\"\"Normalize audio to target sample rate and loudness.\"\"\"\n",
        "    \n",
        "    def __init__(self, target_sr: int = TARGET_SR, target_lufs: float = TARGET_LUFS, peak: float = NORMALIZE_PEAK):\n",
        "        self.target_sr = target_sr\n",
        "        self.target_lufs = target_lufs\n",
        "        self.peak = peak\n",
        "    \n",
        "    def normalize(self, audio_path: Path) -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Load and normalize audio file.\"\"\"\n",
        "        # Load audio\n",
        "        audio, sr = librosa.load(str(audio_path), sr=self.target_sr, mono=True)\n",
        "        \n",
        "        # Peak normalization\n",
        "        peak_val = np.max(np.abs(audio))\n",
        "        if peak_val > 0:\n",
        "            audio = audio * (self.peak / peak_val)\n",
        "        \n",
        "        # LUFS normalization (simplified - using RMS approximation)\n",
        "        # For production, use pyloudnorm or similar\n",
        "        rms = np.sqrt(np.mean(audio**2))\n",
        "        target_rms = 10 ** (self.target_lufs / 20) * 0.1  # Approximate conversion\n",
        "        if rms > 0:\n",
        "            audio = audio * (target_rms / rms)\n",
        "        \n",
        "        # Clip to prevent overflow\n",
        "        audio = np.clip(audio, -1.0, 1.0)\n",
        "        \n",
        "        return audio.astype(np.float32), self.target_sr\n",
        "    \n",
        "    def save_normalized(self, audio: np.ndarray, output_path: Path, sr: int = TARGET_SR):\n",
        "        \"\"\"Save normalized audio to file.\"\"\"\n",
        "        sf.write(str(output_path), audio, sr)\n",
        "\n",
        "\n",
        "class ASRBaseline:\n",
        "    \"\"\"Whisper-based ASR baseline for transcription.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = ASR_MODEL_NAME):\n",
        "        print(f\"Loading Whisper model: {model_name}\")\n",
        "        self.model = whisper.load_model(model_name)\n",
        "        self.model_name = model_name\n",
        "    \n",
        "    def transcribe(self, audio: np.ndarray, sr: int = TARGET_SR) -> str:\n",
        "        \"\"\"Transcribe audio to text.\"\"\"\n",
        "        # Whisper expects float32 audio in range [-1, 1]\n",
        "        if audio.dtype != np.float32:\n",
        "            audio = audio.astype(np.float32)\n",
        "        \n",
        "        # Resample if needed (Whisper expects 16kHz)\n",
        "        if sr != 16000:\n",
        "            audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "        \n",
        "        result = self.model.transcribe(audio, language=\"en\", fp16=False)\n",
        "        return result[\"text\"].strip()\n",
        "    \n",
        "    def compute_wer(self, reference: str, hypothesis: str) -> float:\n",
        "        \"\"\"Compute Word Error Rate (WER).\"\"\"\n",
        "        ref_words = reference.lower().split()\n",
        "        hyp_words = hypothesis.lower().split()\n",
        "        \n",
        "        if len(ref_words) == 0:\n",
        "            return 1.0 if len(hyp_words) > 0 else 0.0\n",
        "        \n",
        "        # Dynamic programming for edit distance\n",
        "        d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1))\n",
        "        for i in range(len(ref_words) + 1):\n",
        "            d[i, 0] = i\n",
        "        for j in range(len(hyp_words) + 1):\n",
        "            d[0, j] = j\n",
        "        \n",
        "        for i in range(1, len(ref_words) + 1):\n",
        "            for j in range(1, len(hyp_words) + 1):\n",
        "                if ref_words[i-1] == hyp_words[j-1]:\n",
        "                    d[i, j] = d[i-1, j-1]\n",
        "                else:\n",
        "                    d[i, j] = min(\n",
        "                        d[i-1, j] + 1,      # deletion\n",
        "                        d[i, j-1] + 1,      # insertion\n",
        "                        d[i-1, j-1] + 1     # substitution\n",
        "                    )\n",
        "        \n",
        "        return d[len(ref_words), len(hyp_words)] / len(ref_words)\n",
        "    \n",
        "    def compute_cer(self, reference: str, hypothesis: str) -> float:\n",
        "        \"\"\"Compute Character Error Rate (CER).\"\"\"\n",
        "        ref_chars = list(reference.lower().replace(\" \", \"\"))\n",
        "        hyp_chars = list(hypothesis.lower().replace(\" \", \"\"))\n",
        "        \n",
        "        if len(ref_chars) == 0:\n",
        "            return 1.0 if len(hyp_chars) > 0 else 0.0\n",
        "        \n",
        "        # Character-level edit distance\n",
        "        d = np.zeros((len(ref_chars) + 1, len(hyp_chars) + 1))\n",
        "        for i in range(len(ref_chars) + 1):\n",
        "            d[i, 0] = i\n",
        "        for j in range(len(hyp_chars) + 1):\n",
        "            d[0, j] = j\n",
        "        \n",
        "        for i in range(1, len(ref_chars) + 1):\n",
        "            for j in range(1, len(hyp_chars) + 1):\n",
        "                if ref_chars[i-1] == hyp_chars[j-1]:\n",
        "                    d[i, j] = d[i-1, j-1]\n",
        "                else:\n",
        "                    d[i, j] = min(\n",
        "                        d[i-1, j] + 1,\n",
        "                        d[i, j-1] + 1,\n",
        "                        d[i-1, j-1] + 1\n",
        "                    )\n",
        "        \n",
        "        return d[len(ref_chars), len(hyp_chars)] / len(ref_chars)\n",
        "\n",
        "\n",
        "# Initialize components\n",
        "normalizer = AudioNormalizer()\n",
        "asr_baseline = ASRBaseline()\n",
        "\n",
        "print(\"Audio normalizer and ASR baseline initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CodecDetector:\n",
        "    \"\"\"Detect codec information from audio files.\"\"\"\n",
        "    \n",
        "    def detect(self, audio_path: Path) -> Dict[str, Any]:\n",
        "        \"\"\"Detect codec using ffprobe.\"\"\"\n",
        "        try:\n",
        "            cmd = [\n",
        "                \"ffprobe\", \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\",\n",
        "                \"-show_streams\", str(audio_path)\n",
        "            ]\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "            data = json.loads(result.stdout)\n",
        "            \n",
        "            # Extract codec info\n",
        "            stream = data.get(\"streams\", [{}])[0]\n",
        "            format_info = data.get(\"format\", {})\n",
        "            \n",
        "            codec_name = stream.get(\"codec_name\", \"unknown\")\n",
        "            bitrate = int(format_info.get(\"bit_rate\", 0)) // 1000  # Convert to kbps\n",
        "            sample_rate = int(stream.get(\"sample_rate\", TARGET_SR))\n",
        "            channels = int(stream.get(\"channels\", 1))\n",
        "            container = format_info.get(\"format_name\", \"\").split(\",\")[0]\n",
        "            \n",
        "            return {\n",
        "                \"codec_name\": codec_name,\n",
        "                \"bitrate_kbps\": bitrate,\n",
        "                \"sample_rate\": sample_rate,\n",
        "                \"channels\": channels,\n",
        "                \"container\": container,\n",
        "                \"detected\": True\n",
        "            }\n",
        "        except Exception as e:\n",
        "            # Fallback to heuristic detection\n",
        "            ext = audio_path.suffix.lower()\n",
        "            mapping = {\n",
        "                \".wav\": {\"codec_name\": \"pcm\", \"bitrate_kbps\": 1411},\n",
        "                \".mp3\": {\"codec_name\": \"mp3\", \"bitrate_kbps\": 192},\n",
        "                \".m4a\": {\"codec_name\": \"aac\", \"bitrate_kbps\": 256},\n",
        "                \".flac\": {\"codec_name\": \"flac\", \"bitrate_kbps\": 1000},\n",
        "                \".opus\": {\"codec_name\": \"opus\", \"bitrate_kbps\": 96}\n",
        "            }\n",
        "            default = mapping.get(ext, {\"codec_name\": \"unknown\", \"bitrate_kbps\": 128})\n",
        "            return {\n",
        "                **default,\n",
        "                \"sample_rate\": TARGET_SR,\n",
        "                \"channels\": 1,\n",
        "                \"container\": ext.lstrip(\".\"),\n",
        "                \"detected\": False,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "\n",
        "class CodecStack:\n",
        "    \"\"\"Codec stack for transcoding audio.\"\"\"\n",
        "    \n",
        "    # Map codec names to proper file extensions\n",
        "    CODEC_EXTENSIONS = {\n",
        "        \"mp3\": \".mp3\",\n",
        "        \"aac\": \".m4a\",  # AAC typically uses .m4a container\n",
        "        \"opus\": \".opus\",\n",
        "        \"amr-wb\": \".amr\",\n",
        "        \"g711\": \".ulaw\"\n",
        "    }\n",
        "    \n",
        "    def __init__(self, codecs: Dict[str, Dict] = CODECS):\n",
        "        self.codecs = codecs\n",
        "    \n",
        "    def _get_output_path(self, output_path: Path, codec_name: str) -> Path:\n",
        "        \"\"\"Ensure output path has proper extension for codec.\"\"\"\n",
        "        ext = self.CODEC_EXTENSIONS.get(codec_name, \".tmp\")\n",
        "        if output_path.suffix != ext:\n",
        "            # Replace extension\n",
        "            return output_path.with_suffix(ext)\n",
        "        return output_path\n",
        "    \n",
        "    def encode(self, audio_path: Path, codec_name: str, bitrate: Any, output_path: Path) -> bool:\n",
        "        \"\"\"Encode audio using specified codec and bitrate.\"\"\"\n",
        "        if codec_name not in self.codecs:\n",
        "            raise ValueError(f\"Unsupported codec: {codec_name}\")\n",
        "        \n",
        "        codec_info = self.codecs[codec_name]\n",
        "        codec = codec_info[\"codec\"]\n",
        "        \n",
        "        # Ensure proper file extension\n",
        "        output_path = self._get_output_path(output_path, codec_name)\n",
        "        \n",
        "        try:\n",
        "            # Build ffmpeg command\n",
        "            cmd = [\n",
        "                \"ffmpeg\", \"-y\", \"-i\", str(audio_path),\n",
        "                \"-acodec\", codec,\n",
        "                \"-ar\", str(TARGET_SR),\n",
        "                \"-ac\", \"1\"  # Mono\n",
        "            ]\n",
        "            \n",
        "            # Add bitrate and format-specific options\n",
        "            if codec_name == \"g711\":\n",
        "                # G.711 is fixed bitrate\n",
        "                cmd.extend([\"-f\", \"mulaw\"])\n",
        "            elif codec_name == \"amr-wb\":\n",
        "                cmd.extend([\"-b:a\", f\"{bitrate}k\"])\n",
        "            elif codec_name == \"aac\":\n",
        "                # AAC needs explicit format\n",
        "                cmd.extend([\"-b:a\", f\"{bitrate}k\", \"-f\", \"ipod\"])\n",
        "            else:\n",
        "                cmd.extend([\"-b:a\", f\"{bitrate}k\"])\n",
        "            \n",
        "            cmd.append(str(output_path))\n",
        "            \n",
        "            # Run encoding\n",
        "            result = subprocess.run(\n",
        "                cmd, capture_output=True, text=True, check=True\n",
        "            )\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Encoding failed: {e.stderr}\")\n",
        "            return False\n",
        "    \n",
        "    def decode(self, encoded_path: Path, output_path: Path) -> bool:\n",
        "        \"\"\"Decode encoded audio back to WAV.\"\"\"\n",
        "        try:\n",
        "            cmd = [\n",
        "                \"ffmpeg\", \"-y\", \"-i\", str(encoded_path),\n",
        "                \"-acodec\", \"pcm_s16le\",\n",
        "                \"-ar\", str(TARGET_SR),\n",
        "                \"-ac\", \"1\",\n",
        "                str(output_path)\n",
        "            ]\n",
        "            subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Decoding failed: {e.stderr}\")\n",
        "            return False\n",
        "    \n",
        "    def apply_codec_chain(self, audio_path: Path, chain: List[Tuple[str, Any]], \n",
        "                         output_dir: Path) -> Optional[Path]:\n",
        "        \"\"\"Apply a chain of codec transformations.\"\"\"\n",
        "        current_path = audio_path\n",
        "        temp_dir = output_dir / \"temp_codec\"\n",
        "        temp_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        final_output = None\n",
        "        for i, (codec_name, bitrate) in enumerate(chain):\n",
        "            temp_output = temp_dir / f\"chain_{i}_{codec_name}_{bitrate}.tmp\"\n",
        "            \n",
        "            # Encode (this will automatically fix the extension)\n",
        "            if not self.encode(current_path, codec_name, bitrate, temp_output):\n",
        "                return None\n",
        "            \n",
        "            # Get the actual output path with correct extension\n",
        "            actual_output = self._get_output_path(temp_output, codec_name)\n",
        "            final_output = actual_output\n",
        "            \n",
        "            # Decode for next step\n",
        "            if i < len(chain) - 1:\n",
        "                temp_decoded = temp_dir / f\"chain_{i}_decoded.wav\"\n",
        "                if not self.decode(actual_output, temp_decoded):\n",
        "                    return None\n",
        "                current_path = temp_decoded\n",
        "        \n",
        "        return final_output if len(chain) == 1 else current_path\n",
        "\n",
        "\n",
        "# Initialize codec components\n",
        "codec_detector = CodecDetector()\n",
        "codec_stack = CodecStack()\n",
        "\n",
        "print(\"Codec detector and stack initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "@dataclass\n",
        "class PerturbationStrategy:\n",
        "    \"\"\"Structured perturbation strategy from LLM.\"\"\"\n",
        "    name: str\n",
        "    family: str  # e.g., \"narrowband_spectral_noise\", \"phase_only\", \"micro_time_warp\", \"spread_spectrum\"\n",
        "    optimizer: str  # e.g., \"CMA-ES\", \"gradient\", \"black_box\"\n",
        "    constraints: Dict[str, float]\n",
        "    eot_schedule: Dict[str, Any]\n",
        "    code_snippet: str\n",
        "    parameters: Dict[str, Any] = field(default_factory=dict)\n",
        "    description: str = \"\"\n",
        "\n",
        "\n",
        "class LLMOrchestrator:\n",
        "    \"\"\"Gemini 3-based LLM orchestrator for strategy generation.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = None):\n",
        "        # Try Gemini 3 models in order of preference\n",
        "        gemini_models = [\n",
        "            \"gemini-2.0-flash-exp\",  # Latest experimental\n",
        "            \"gemini-1.5-pro\",        # Gemini 1.5 Pro\n",
        "            \"gemini-1.5-flash\",      # Gemini 1.5 Flash\n",
        "            \"gemini-pro\"             # Fallback\n",
        "        ]\n",
        "        \n",
        "        if model_name:\n",
        "            gemini_models.insert(0, model_name)\n",
        "        \n",
        "        self.model = None\n",
        "        self.model_name = None\n",
        "        \n",
        "        for model in gemini_models:\n",
        "            try:\n",
        "                self.model = genai.GenerativeModel(model)\n",
        "                self.model_name = model\n",
        "                print(f\"Successfully loaded Gemini model: {model}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load {model}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Failed to load any Gemini model. Please check your API key and model availability.\")\n",
        "    \n",
        "    def generate_strategy(\n",
        "        self,\n",
        "        codec_info: Dict[str, Any],\n",
        "        available_codecs: Dict[str, Dict],\n",
        "        previous_feedback: Optional[str] = None,\n",
        "        iteration: int = 1\n",
        "    ) -> PerturbationStrategy:\n",
        "        \"\"\"Generate perturbation strategy based on codec information.\"\"\"\n",
        "        \n",
        "        # Build prompt\n",
        "        prompt = self._build_strategy_prompt(\n",
        "            codec_info, available_codecs, previous_feedback, iteration\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            strategy_text = response.text\n",
        "            \n",
        "            # Parse strategy from response\n",
        "            strategy = self._parse_strategy(strategy_text, codec_info)\n",
        "            return strategy\n",
        "        except Exception as e:\n",
        "            print(f\"LLM generation failed: {e}\")\n",
        "            # Return default strategy\n",
        "            return self._default_strategy(codec_info)\n",
        "    \n",
        "    def _build_strategy_prompt(\n",
        "        self,\n",
        "        codec_info: Dict[str, Any],\n",
        "        available_codecs: Dict[str, Dict],\n",
        "        previous_feedback: Optional[str],\n",
        "        iteration: int\n",
        "    ) -> str:\n",
        "        \"\"\"Build prompt for strategy generation.\"\"\"\n",
        "        \n",
        "        codec_list = \", \".join([f\"{k} (bitrates: {v['bitrates']})\" \n",
        "                                for k, v in available_codecs.items()])\n",
        "        \n",
        "        feedback_section = \"\"\n",
        "        if previous_feedback:\n",
        "            feedback_section = f\"\"\"\n",
        "Previous iteration feedback:\n",
        "{previous_feedback}\n",
        "\n",
        "Based on this feedback, revise your strategy.\n",
        "\"\"\"\n",
        "        \n",
        "        prompt = f\"\"\"You are an expert in adversarial audio generation for ASR systems. Your task is to design perturbation strategies that survive lossy codec compression.\n",
        "\n",
        "Current codec context:\n",
        "- Detected codec: {codec_info.get('codec_name', 'unknown')}\n",
        "- Bitrate: {codec_info.get('bitrate_kbps', 'unknown')} kbps\n",
        "- Sample rate: {codec_info.get('sample_rate', TARGET_SR)} Hz\n",
        "\n",
        "Available codecs for EoT (Expectation over Transformations):\n",
        "{codec_list}\n",
        "\n",
        "Constraints:\n",
        "- Maximum L∞ norm: {MAX_LINF}\n",
        "- Maximum L2 norm: {MAX_L2}\n",
        "- Minimum PESQ: {MIN_PESQ}\n",
        "- Minimum STOI: {MIN_STOI}\n",
        "- Minimum SNR: {MIN_SNR} dB\n",
        "- Target SNR: {TARGET_SNR} dB\n",
        "\n",
        "{feedback_section}\n",
        "\n",
        "Generate a perturbation strategy in the following JSON format:\n",
        "{{\n",
        "    \"name\": \"strategy_name\",\n",
        "    \"family\": \"narrowband_spectral_noise|phase_only|micro_time_warp|spread_spectrum|hybrid\",\n",
        "    \"optimizer\": \"CMA-ES|gradient|black_box\",\n",
        "    \"constraints\": {{\n",
        "        \"max_linf\": {MAX_LINF},\n",
        "        \"max_l2\": {MAX_L2},\n",
        "        \"min_pesq\": {MIN_PESQ},\n",
        "        \"min_stoi\": {MIN_STOI},\n",
        "        \"min_snr\": {MIN_SNR},\n",
        "        \"target_snr\": {TARGET_SNR}\n",
        "    }},\n",
        "    \"eot_schedule\": {{\n",
        "        \"num_samples\": {EOT_NUM_SAMPLES},\n",
        "        \"codec_mix\": [\"mp3\", \"aac\", \"opus\"],\n",
        "        \"bitrate_range\": [64, 256],\n",
        "        \"chain_length\": {EOT_CHAIN_LENGTH},\n",
        "        \"chain_probability\": 0.3\n",
        "    }},\n",
        "    \"parameters\": {{\n",
        "        \"frequency_bands\": [3000, 4000],\n",
        "        \"noise_level\": 0.005,\n",
        "        \"time_warp_factor\": 0.01\n",
        "    }},\n",
        "    \"code_snippet\": \"Python code implementing the perturbation\",\n",
        "    \"description\": \"Detailed description of the strategy\"\n",
        "}}\n",
        "\n",
        "Focus on strategies that:\n",
        "1. Exploit codec-specific vulnerabilities (e.g., MP3's frequency masking, AAC's temporal windows)\n",
        "2. Use frequency-domain perturbations that survive quantization\n",
        "3. Apply phase-only modifications that are less perceptible\n",
        "4. Leverage EoT to ensure robustness across codec chains\n",
        "\n",
        "Return ONLY the JSON, no additional text.\"\"\"\n",
        "        \n",
        "        return prompt\n",
        "    \n",
        "    def _parse_strategy(self, response_text: str, codec_info: Dict[str, Any]) -> PerturbationStrategy:\n",
        "        \"\"\"Parse strategy from LLM response.\"\"\"\n",
        "        try:\n",
        "            # Extract JSON from response\n",
        "            import re\n",
        "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                strategy_dict = json.loads(json_match.group())\n",
        "            else:\n",
        "                raise ValueError(\"No JSON found in response\")\n",
        "            \n",
        "            return PerturbationStrategy(\n",
        "                name=strategy_dict.get(\"name\", \"default_strategy\"),\n",
        "                family=strategy_dict.get(\"family\", \"narrowband_spectral_noise\"),\n",
        "                optimizer=strategy_dict.get(\"optimizer\", \"CMA-ES\"),\n",
        "                constraints=strategy_dict.get(\"constraints\", {}),\n",
        "                eot_schedule=strategy_dict.get(\"eot_schedule\", {}),\n",
        "                code_snippet=strategy_dict.get(\"code_snippet\", \"\"),\n",
        "                parameters=strategy_dict.get(\"parameters\", {}),\n",
        "                description=strategy_dict.get(\"description\", \"\")\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to parse strategy: {e}\")\n",
        "            return self._default_strategy(codec_info)\n",
        "    \n",
        "    def _default_strategy(self, codec_info: Dict[str, Any]) -> PerturbationStrategy:\n",
        "        \"\"\"Return default strategy if LLM fails.\"\"\"\n",
        "        return PerturbationStrategy(\n",
        "            name=\"default_narrowband_noise\",\n",
        "            family=\"narrowband_spectral_noise\",\n",
        "            optimizer=\"CMA-ES\",\n",
        "            constraints={\n",
        "                \"max_linf\": MAX_LINF,\n",
        "                \"max_l2\": MAX_L2,\n",
        "                \"min_pesq\": MIN_PESQ,\n",
        "                \"min_stoi\": MIN_STOI,\n",
        "                \"min_snr\": MIN_SNR,\n",
        "                \"target_snr\": TARGET_SNR\n",
        "            },\n",
        "            eot_schedule={\n",
        "                \"num_samples\": EOT_NUM_SAMPLES,\n",
        "                \"codec_mix\": [\"mp3\", \"aac\"],\n",
        "                \"bitrate_range\": [64, 192],\n",
        "                \"chain_length\": 2,\n",
        "                \"chain_probability\": 0.2\n",
        "            },\n",
        "            code_snippet=\"\"\"\n",
        "def apply_perturbation(audio, sr=16000):\n",
        "    # Narrowband noise injection\n",
        "    noise = np.random.randn(len(audio)) * 0.005\n",
        "    # Filter to 3-4 kHz band\n",
        "    from scipy import signal\n",
        "    b, a = signal.butter(4, [3000/(sr/2), 4000/(sr/2)], btype='band')\n",
        "    noise = signal.filtfilt(b, a, noise)\n",
        "    return audio + noise\n",
        "            \"\"\",\n",
        "            parameters={\"frequency_bands\": [3000, 4000], \"noise_level\": 0.005},\n",
        "            description=\"Default narrowband spectral noise injection\"\n",
        "        )\n",
        "    \n",
        "    def generate_feedback_summary(\n",
        "        self,\n",
        "        results: List[Dict[str, Any]],\n",
        "        top_k: int = STRATEGY_TOP_K\n",
        "    ) -> str:\n",
        "        \"\"\"Generate feedback summary for LLM based on results.\"\"\"\n",
        "        if not results:\n",
        "            return \"No results available yet.\"\n",
        "        \n",
        "        # Sort by WER increase (best attacks first)\n",
        "        sorted_results = sorted(\n",
        "            results,\n",
        "            key=lambda x: x.get(\"wer_delta\", 0),\n",
        "            reverse=True\n",
        "        )\n",
        "        \n",
        "        top_results = sorted_results[:top_k]\n",
        "        \n",
        "        summary = f\"Top {len(top_results)} strategies:\\n\\n\"\n",
        "        for i, result in enumerate(top_results, 1):\n",
        "            summary += f\"{i}. {result.get('strategy_name', 'unknown')}:\\n\"\n",
        "            summary += f\"   - WER delta: {result.get('wer_delta', 0):.3f}\\n\"\n",
        "            summary += f\"   - CER delta: {result.get('cer_delta', 0):.3f}\\n\"\n",
        "            summary += f\"   - PESQ: {result.get('pesq', 0):.2f}\\n\"\n",
        "            summary += f\"   - STOI: {result.get('stoi', 0):.3f}\\n\"\n",
        "            summary += f\"   - SNR: {result.get('snr', 0):.2f} dB\\n\"\n",
        "            summary += f\"   - Codec: {result.get('codec', 'unknown')}\\n\\n\"\n",
        "        \n",
        "        # Failure modes\n",
        "        failures = [r for r in results if r.get(\"wer_delta\", 0) < 0.1]\n",
        "        if failures:\n",
        "            summary += f\"\\nFailure modes ({len(failures)} strategies):\\n\"\n",
        "            summary += \"- Low WER increase despite perturbation\\n\"\n",
        "            summary += \"- Constraint violations (PESQ/STOI too low)\\n\"\n",
        "            summary += \"- Codec-specific robustness issues\\n\"\n",
        "        \n",
        "        return summary\n",
        "\n",
        "\n",
        "# Initialize LLM orchestrator\n",
        "llm_orchestrator = LLMOrchestrator()\n",
        "\n",
        "print(\"LLM orchestrator initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PerturbationExecutor:\n",
        "    \"\"\"Execute perturbation strategies on audio.\"\"\"\n",
        "    \n",
        "    def __init__(self, codec_stack: CodecStack, normalizer: AudioNormalizer):\n",
        "        self.codec_stack = codec_stack\n",
        "        self.normalizer = normalizer\n",
        "    \n",
        "    def apply_perturbation(\n",
        "        self,\n",
        "        audio: np.ndarray,\n",
        "        strategy: PerturbationStrategy,\n",
        "        sr: int = TARGET_SR\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"Apply perturbation based on strategy.\"\"\"\n",
        "        # Execute the code snippet from strategy\n",
        "        try:\n",
        "            # Create execution context\n",
        "            exec_globals = {\n",
        "                \"np\": np,\n",
        "                \"librosa\": librosa,\n",
        "                \"audio\": audio.copy(),\n",
        "                \"sr\": sr,\n",
        "                \"strategy\": strategy\n",
        "            }\n",
        "            \n",
        "            # Execute code snippet\n",
        "            exec(strategy.code_snippet, exec_globals)\n",
        "            \n",
        "            # Get perturbed audio (assuming function returns it)\n",
        "            if \"perturbed_audio\" in exec_globals:\n",
        "                perturbed = exec_globals[\"perturbed_audio\"]\n",
        "            elif \"result\" in exec_globals:\n",
        "                perturbed = exec_globals[\"result\"]\n",
        "            else:\n",
        "                # Fallback: apply default perturbation\n",
        "                perturbed = self._apply_default_perturbation(audio, strategy, sr)\n",
        "            \n",
        "            # Ensure constraints\n",
        "            perturbed = self._enforce_constraints(audio, perturbed, strategy)\n",
        "            \n",
        "            return perturbed.astype(np.float32)\n",
        "        except Exception as e:\n",
        "            print(f\"Perturbation execution failed: {e}\")\n",
        "            return self._apply_default_perturbation(audio, strategy, sr)\n",
        "    \n",
        "    def _apply_default_perturbation(\n",
        "        self,\n",
        "        audio: np.ndarray,\n",
        "        strategy: PerturbationStrategy,\n",
        "        sr: int\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"Apply default perturbation based on family.\"\"\"\n",
        "        family = strategy.family.lower()\n",
        "        params = strategy.parameters\n",
        "        \n",
        "        if \"narrowband\" in family or \"spectral\" in family:\n",
        "            # Narrowband spectral noise\n",
        "            noise_level = params.get(\"noise_level\", 0.005)\n",
        "            freq_bands = params.get(\"frequency_bands\", [3000, 4000])\n",
        "            \n",
        "            from scipy import signal\n",
        "            noise = np.random.randn(len(audio)) * noise_level\n",
        "            b, a = signal.butter(4, [freq_bands[0]/(sr/2), freq_bands[1]/(sr/2)], btype='band')\n",
        "            noise = signal.filtfilt(b, a, noise)\n",
        "            return audio + noise\n",
        "        \n",
        "        elif \"phase\" in family:\n",
        "            # Phase-only modification\n",
        "            fft = np.fft.fft(audio)\n",
        "            magnitude = np.abs(fft)\n",
        "            phase = np.angle(fft)\n",
        "            phase_shift = params.get(\"phase_shift\", 0.01) * np.random.randn(len(phase))\n",
        "            new_fft = magnitude * np.exp(1j * (phase + phase_shift))\n",
        "            return np.real(np.fft.ifft(new_fft))\n",
        "        \n",
        "        elif \"time_warp\" in family:\n",
        "            # Micro time warping\n",
        "            from scipy.interpolate import interp1d\n",
        "            warp_factor = params.get(\"time_warp_factor\", 0.01)\n",
        "            n = len(audio)\n",
        "            indices = np.arange(n) + warp_factor * np.sin(2 * np.pi * np.arange(n) / (n/10))\n",
        "            indices = np.clip(indices, 0, n-1)\n",
        "            f = interp1d(np.arange(n), audio, kind='linear', fill_value='extrapolate')\n",
        "            return f(indices)\n",
        "        \n",
        "        elif \"spread_spectrum\" in family:\n",
        "            # Spread spectrum pattern\n",
        "            noise_level = params.get(\"noise_level\", 0.003)\n",
        "            noise = np.random.randn(len(audio)) * noise_level\n",
        "            # Modulate with chirp\n",
        "            t = np.arange(len(audio)) / sr\n",
        "            chirp = np.sin(2 * np.pi * (1000 + 2000 * t) * t)\n",
        "            noise = noise * (1 + 0.1 * chirp)\n",
        "            return audio + noise\n",
        "        \n",
        "        else:\n",
        "            # Default: additive Gaussian noise\n",
        "            noise_level = params.get(\"noise_level\", 0.005)\n",
        "            noise = np.random.randn(len(audio)) * noise_level\n",
        "            return audio + noise\n",
        "    \n",
        "    def _enforce_constraints(\n",
        "        self,\n",
        "        original: np.ndarray,\n",
        "        perturbed: np.ndarray,\n",
        "        strategy: PerturbationStrategy\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"Enforce perturbation constraints.\"\"\"\n",
        "        constraints = strategy.constraints\n",
        "        perturbation = perturbed - original\n",
        "        \n",
        "        # L∞ constraint\n",
        "        max_linf = constraints.get(\"max_linf\", MAX_LINF)\n",
        "        if np.max(np.abs(perturbation)) > max_linf:\n",
        "            perturbation = perturbation * (max_linf / np.max(np.abs(perturbation)))\n",
        "        \n",
        "        # L2 constraint\n",
        "        max_l2 = constraints.get(\"max_l2\", MAX_L2)\n",
        "        l2_norm = np.linalg.norm(perturbation)\n",
        "        if l2_norm > max_l2:\n",
        "            perturbation = perturbation * (max_l2 / l2_norm)\n",
        "        \n",
        "        perturbed = original + perturbation\n",
        "        return np.clip(perturbed, -1.0, 1.0)\n",
        "    \n",
        "    def apply_eot(\n",
        "        self,\n",
        "        audio: np.ndarray,\n",
        "        strategy: PerturbationStrategy,\n",
        "        output_dir: Path,\n",
        "        sr: int = TARGET_SR\n",
        "    ) -> List[Tuple[np.ndarray, Dict[str, Any]]]:\n",
        "        \"\"\"Apply Expectation over Transformations.\"\"\"\n",
        "        eot_schedule = strategy.eot_schedule\n",
        "        num_samples = eot_schedule.get(\"num_samples\", EOT_NUM_SAMPLES)\n",
        "        codec_mix = eot_schedule.get(\"codec_mix\", [\"mp3\", \"aac\"])\n",
        "        bitrate_range = eot_schedule.get(\"bitrate_range\", [64, 192])\n",
        "        chain_length = eot_schedule.get(\"chain_length\", EOT_CHAIN_LENGTH)\n",
        "        chain_prob = eot_schedule.get(\"chain_probability\", 0.3)\n",
        "        \n",
        "        results = []\n",
        "        temp_dir = output_dir / \"eot_temp\"\n",
        "        temp_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        # Save original perturbed audio\n",
        "        temp_original = temp_dir / \"perturbed_original.wav\"\n",
        "        sf.write(str(temp_original), audio, sr)\n",
        "        \n",
        "        for i in range(num_samples):\n",
        "            # Decide on chain vs single codec\n",
        "            use_chain = np.random.random() < chain_prob and chain_length > 1\n",
        "            \n",
        "            if use_chain:\n",
        "                # Generate codec chain\n",
        "                chain = []\n",
        "                for _ in range(np.random.randint(2, chain_length + 1)):\n",
        "                    codec = np.random.choice(codec_mix)\n",
        "                    bitrate = np.random.choice(CODECS[codec][\"bitrates\"])\n",
        "                    chain.append((codec, bitrate))\n",
        "                \n",
        "                # Apply chain\n",
        "                transformed_path = self.codec_stack.apply_codec_chain(\n",
        "                    temp_original, chain, temp_dir\n",
        "                )\n",
        "            else:\n",
        "                # Single codec transformation\n",
        "                codec = np.random.choice(codec_mix)\n",
        "                bitrate = np.random.choice(CODECS[codec][\"bitrates\"])\n",
        "                transformed_path = temp_dir / f\"eot_{i}_{codec}_{bitrate}.tmp\"\n",
        "                if self.codec_stack.encode(temp_original, codec, bitrate, transformed_path):\n",
        "                    # Get the actual path with correct extension\n",
        "                    transformed_path = self.codec_stack._get_output_path(transformed_path, codec)\n",
        "                else:\n",
        "                    transformed_path = None\n",
        "            \n",
        "            if transformed_path and transformed_path.exists():\n",
        "                # Decode back to audio\n",
        "                decoded_path = temp_dir / f\"eot_{i}_decoded.wav\"\n",
        "                if self.codec_stack.decode(transformed_path, decoded_path):\n",
        "                    transformed_audio, _ = self.normalizer.normalize(decoded_path)\n",
        "                    \n",
        "                    metadata = {\n",
        "                        \"sample_idx\": i,\n",
        "                        \"codec\": codec if not use_chain else \"chain\",\n",
        "                        \"bitrate\": bitrate if not use_chain else None,\n",
        "                        \"chain\": chain if use_chain else None\n",
        "                    }\n",
        "                    results.append((transformed_audio, metadata))\n",
        "        \n",
        "        return results\n",
        "\n",
        "\n",
        "# Initialize executor\n",
        "perturbation_executor = PerturbationExecutor(codec_stack, normalizer)\n",
        "\n",
        "print(\"Perturbation executor initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MetricsComputer:\n",
        "    \"\"\"Compute all evaluation metrics.\"\"\"\n",
        "    \n",
        "    def __init__(self, asr_baseline: ASRBaseline):\n",
        "        self.asr = asr_baseline\n",
        "    \n",
        "    def compute_all_metrics(\n",
        "        self,\n",
        "        original_audio: np.ndarray,\n",
        "        perturbed_audio: np.ndarray,\n",
        "        original_transcript: str,\n",
        "        sr: int = TARGET_SR\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Compute all metrics for a perturbed audio sample.\"\"\"\n",
        "        metrics = {}\n",
        "        \n",
        "        # ASR metrics\n",
        "        perturbed_transcript = self.asr.transcribe(perturbed_audio, sr)\n",
        "        metrics[\"wer\"] = self.asr.compute_wer(original_transcript, perturbed_transcript)\n",
        "        metrics[\"cer\"] = self.asr.compute_cer(original_transcript, perturbed_transcript)\n",
        "        metrics[\"perturbed_transcript\"] = perturbed_transcript\n",
        "        \n",
        "        # Perceptual quality metrics\n",
        "        min_len = min(len(original_audio), len(perturbed_audio))\n",
        "        orig_trimmed = original_audio[:min_len]\n",
        "        pert_trimmed = perturbed_audio[:min_len]\n",
        "        \n",
        "        try:\n",
        "            metrics[\"pesq\"] = pesq(sr, orig_trimmed, pert_trimmed, 'wb')\n",
        "        except:\n",
        "            metrics[\"pesq\"] = 0.0\n",
        "        \n",
        "        try:\n",
        "            metrics[\"stoi\"] = stoi(orig_trimmed, pert_trimmed, sr, extended=False)\n",
        "        except:\n",
        "            metrics[\"stoi\"] = 0.0\n",
        "        \n",
        "        # Signal metrics\n",
        "        perturbation = pert_trimmed - orig_trimmed\n",
        "        signal_power = np.mean(orig_trimmed ** 2)\n",
        "        noise_power = np.mean(perturbation ** 2)\n",
        "        if noise_power > 0:\n",
        "            metrics[\"snr\"] = 10 * np.log10(signal_power / noise_power)\n",
        "        else:\n",
        "            metrics[\"snr\"] = float('inf')\n",
        "        \n",
        "        # LUFS (simplified RMS-based approximation)\n",
        "        rms_pert = np.sqrt(np.mean(pert_trimmed ** 2))\n",
        "        metrics[\"lufs\"] = 20 * np.log10(rms_pert / 0.1) if rms_pert > 0 else -np.inf\n",
        "        \n",
        "        # Norms\n",
        "        metrics[\"l2_norm\"] = np.linalg.norm(perturbation)\n",
        "        metrics[\"linf_norm\"] = np.max(np.abs(perturbation))\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def compute_baseline_metrics(\n",
        "        self,\n",
        "        original_audio: np.ndarray,\n",
        "        original_transcript: str,\n",
        "        sr: int = TARGET_SR\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Compute baseline metrics for original audio.\"\"\"\n",
        "        # Verify transcription\n",
        "        verified_transcript = self.asr.transcribe(original_audio, sr)\n",
        "        wer = self.asr.compute_wer(original_transcript, verified_transcript)\n",
        "        cer = self.asr.compute_cer(original_transcript, verified_transcript)\n",
        "        \n",
        "        return {\n",
        "            \"wer\": wer,\n",
        "            \"cer\": cer,\n",
        "            \"transcript\": verified_transcript,\n",
        "            \"snr\": float('inf'),  # No noise in original\n",
        "            \"pesq\": 5.0,  # Perfect quality\n",
        "            \"stoi\": 1.0   # Perfect intelligibility\n",
        "        }\n",
        "    \n",
        "    def compute_delta_metrics(\n",
        "        self,\n",
        "        baseline: Dict[str, float],\n",
        "        perturbed: Dict[str, float]\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Compute delta metrics (perturbed - baseline).\"\"\"\n",
        "        return {\n",
        "            \"wer_delta\": perturbed[\"wer\"] - baseline[\"wer\"],\n",
        "            \"cer_delta\": perturbed[\"cer\"] - baseline[\"cer\"],\n",
        "            \"pesq_delta\": perturbed[\"pesq\"] - baseline[\"pesq\"],\n",
        "            \"stoi_delta\": perturbed[\"stoi\"] - baseline[\"stoi\"],\n",
        "            \"snr_delta\": perturbed[\"snr\"] - baseline[\"snr\"] if baseline[\"snr\"] != float('inf') else -perturbed[\"snr\"]\n",
        "        }\n",
        "\n",
        "\n",
        "# Initialize metrics computer\n",
        "metrics_computer = MetricsComputer(asr_baseline)\n",
        "\n",
        "print(\"Metrics computer initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6-8: Main Orchestration Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ExperimentResult:\n",
        "    \"\"\"Results from a single experiment run.\"\"\"\n",
        "    audio_file: str\n",
        "    strategy_name: str\n",
        "    iteration: int\n",
        "    baseline_metrics: Dict[str, float]\n",
        "    perturbed_metrics: Dict[str, float]\n",
        "    eot_results: List[Dict[str, Any]]\n",
        "    delta_metrics: Dict[str, float]\n",
        "    codec_info: Dict[str, Any]\n",
        "    strategy: Dict[str, Any]\n",
        "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
        "\n",
        "\n",
        "class AgentOrchestrator:\n",
        "    \"\"\"Main orchestrator for the entire pipeline.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        normalizer: AudioNormalizer,\n",
        "        asr_baseline: ASRBaseline,\n",
        "        codec_detector: CodecDetector,\n",
        "        codec_stack: CodecStack,\n",
        "        llm_orchestrator: LLMOrchestrator,\n",
        "        perturbation_executor: PerturbationExecutor,\n",
        "        metrics_computer: MetricsComputer\n",
        "    ):\n",
        "        self.normalizer = normalizer\n",
        "        self.asr_baseline = asr_baseline\n",
        "        self.codec_detector = codec_detector\n",
        "        self.codec_stack = codec_stack\n",
        "        self.llm_orchestrator = llm_orchestrator\n",
        "        self.perturbation_executor = perturbation_executor\n",
        "        self.metrics_computer = metrics_computer\n",
        "    \n",
        "    def run_experiment(\n",
        "        self,\n",
        "        audio_path: Path,\n",
        "        reference_transcript: Optional[str] = None,\n",
        "        max_iterations: int = MAX_ITERATIONS\n",
        "    ) -> List[ExperimentResult]:\n",
        "        \"\"\"Run full experiment pipeline.\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Starting experiment for: {audio_path.name}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        \n",
        "        # Step 1: Normalize audio\n",
        "        print(\"Step 1: Normalizing audio...\")\n",
        "        original_audio, sr = self.normalizer.normalize(audio_path)\n",
        "        print(f\"  Loaded audio: {len(original_audio)/sr:.2f}s, {sr} Hz\")\n",
        "        \n",
        "        # Get or generate reference transcript\n",
        "        if reference_transcript is None:\n",
        "            print(\"  Generating reference transcript...\")\n",
        "            reference_transcript = self.asr_baseline.transcribe(original_audio, sr)\n",
        "        print(f\"  Reference: '{reference_transcript}'\")\n",
        "        \n",
        "        # Compute baseline metrics\n",
        "        print(\"\\nStep 2: Computing baseline metrics...\")\n",
        "        baseline_metrics = self.metrics_computer.compute_baseline_metrics(\n",
        "            original_audio, reference_transcript, sr\n",
        "        )\n",
        "        print(f\"  Baseline WER: {baseline_metrics['wer']:.3f}\")\n",
        "        print(f\"  Baseline CER: {baseline_metrics['cer']:.3f}\")\n",
        "        \n",
        "        # Step 2: Detect codec\n",
        "        print(\"\\nStep 3: Detecting codec...\")\n",
        "        codec_info = self.codec_detector.detect(audio_path)\n",
        "        print(f\"  Codec: {codec_info['codec_name']}\")\n",
        "        print(f\"  Bitrate: {codec_info['bitrate_kbps']} kbps\")\n",
        "        \n",
        "        # Main feedback loop\n",
        "        all_results = []\n",
        "        previous_feedback = None\n",
        "        \n",
        "        for iteration in range(1, max_iterations + 1):\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"Iteration {iteration}/{max_iterations}\")\n",
        "            print(f\"{'='*80}\\n\")\n",
        "            \n",
        "            # Show feedback from previous iteration (if any)\n",
        "            if previous_feedback:\n",
        "                print(\"📋 Feedback from previous iteration:\")\n",
        "                print(\"-\" * 80)\n",
        "                print(previous_feedback)\n",
        "                print(\"-\" * 80)\n",
        "                print()\n",
        "            \n",
        "            # Step 3: Generate strategy from LLM\n",
        "            print(\"Step 4: Generating perturbation strategy from LLM...\")\n",
        "            strategy = self.llm_orchestrator.generate_strategy(\n",
        "                codec_info, CODECS, previous_feedback, iteration\n",
        "            )\n",
        "            print(f\"  Strategy: {strategy.name}\")\n",
        "            print(f\"  Family: {strategy.family}\")\n",
        "            print(f\"  Optimizer: {strategy.optimizer}\")\n",
        "            \n",
        "            # Step 4: Apply perturbation\n",
        "            print(\"\\nStep 5: Applying perturbation...\")\n",
        "            perturbed_audio = self.perturbation_executor.apply_perturbation(\n",
        "                original_audio, strategy, sr\n",
        "            )\n",
        "            print(f\"  Perturbation applied: L∞={np.max(np.abs(perturbed_audio - original_audio)):.6f}\")\n",
        "            \n",
        "            # Step 4b: Apply EoT\n",
        "            print(\"\\nStep 6: Applying Expectation over Transformations...\")\n",
        "            eot_outputs = self.perturbation_executor.apply_eot(\n",
        "                perturbed_audio, strategy, ARTIFACTS_DIR, sr\n",
        "            )\n",
        "            print(f\"  Generated {len(eot_outputs)} EoT samples\")\n",
        "            \n",
        "            # Step 5: Compute metrics for perturbed audio\n",
        "            print(\"\\nStep 7: Computing metrics...\")\n",
        "            perturbed_metrics = self.metrics_computer.compute_all_metrics(\n",
        "                original_audio, perturbed_audio, reference_transcript, sr\n",
        "            )\n",
        "            delta_metrics = self.metrics_computer.compute_delta_metrics(\n",
        "                baseline_metrics, perturbed_metrics\n",
        "            )\n",
        "            \n",
        "            print(f\"  WER: {perturbed_metrics['wer']:.3f} (Δ: {delta_metrics['wer_delta']:+.3f})\")\n",
        "            print(f\"  CER: {perturbed_metrics['cer']:.3f} (Δ: {delta_metrics['cer_delta']:+.3f})\")\n",
        "            print(f\"  PESQ: {perturbed_metrics['pesq']:.2f}\")\n",
        "            print(f\"  STOI: {perturbed_metrics['stoi']:.3f}\")\n",
        "            print(f\"  SNR: {perturbed_metrics['snr']:.2f} dB\")\n",
        "            \n",
        "            # Compute metrics for EoT samples\n",
        "            eot_results = []\n",
        "            for eot_audio, eot_metadata in eot_outputs:\n",
        "                eot_metrics = self.metrics_computer.compute_all_metrics(\n",
        "                    original_audio, eot_audio, reference_transcript, sr\n",
        "                )\n",
        "                eot_delta = self.metrics_computer.compute_delta_metrics(\n",
        "                    baseline_metrics, eot_metrics\n",
        "                )\n",
        "                eot_results.append({\n",
        "                    **eot_metadata,\n",
        "                    **eot_metrics,\n",
        "                    **eot_delta\n",
        "                })\n",
        "            \n",
        "            # Create result\n",
        "            result = ExperimentResult(\n",
        "                audio_file=str(audio_path),\n",
        "                strategy_name=strategy.name,\n",
        "                iteration=iteration,\n",
        "                baseline_metrics=baseline_metrics,\n",
        "                perturbed_metrics=perturbed_metrics,\n",
        "                eot_results=eot_results,\n",
        "                delta_metrics=delta_metrics,\n",
        "                codec_info=codec_info,\n",
        "                strategy=asdict(strategy)\n",
        "            )\n",
        "            all_results.append(result)\n",
        "            \n",
        "            # Step 6: Generate feedback for next iteration\n",
        "            print(\"\\nStep 8: Generating feedback summary...\")\n",
        "            feedback_data = [{\n",
        "                \"strategy_name\": strategy.name,\n",
        "                \"wer_delta\": delta_metrics[\"wer_delta\"],\n",
        "                \"cer_delta\": delta_metrics[\"cer_delta\"],\n",
        "                \"pesq\": perturbed_metrics[\"pesq\"],\n",
        "                \"stoi\": perturbed_metrics[\"stoi\"],\n",
        "                \"snr\": perturbed_metrics[\"snr\"],\n",
        "                \"codec\": codec_info[\"codec_name\"]\n",
        "            }]\n",
        "            \n",
        "            previous_feedback = self.llm_orchestrator.generate_feedback_summary(\n",
        "                feedback_data, top_k=1\n",
        "            )\n",
        "            print(f\"\\n📊 Feedback summary for next iteration:\")\n",
        "            print(\"=\" * 80)\n",
        "            print(previous_feedback)\n",
        "            print(\"=\" * 80)\n",
        "            \n",
        "            # Check if we've achieved good results\n",
        "            if delta_metrics[\"wer_delta\"] > 0.3 and perturbed_metrics[\"pesq\"] >= MIN_PESQ:\n",
        "                print(f\"\\n✓ Good results achieved! WER delta: {delta_metrics['wer_delta']:.3f}\")\n",
        "                break\n",
        "        \n",
        "        return all_results\n",
        "    \n",
        "    def save_results(self, results: List[ExperimentResult], output_path: Path):\n",
        "        \"\"\"Save experiment results to JSON.\"\"\"\n",
        "        results_dict = [asdict(r) for r in results]\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(results_dict, f, indent=2, default=str)\n",
        "        print(f\"\\nResults saved to: {output_path}\")\n",
        "    \n",
        "    def save_artifacts(\n",
        "        self,\n",
        "        original_audio: np.ndarray,\n",
        "        perturbed_audio: np.ndarray,\n",
        "        audio_name: str,\n",
        "        strategy_name: str,\n",
        "        iteration: int,\n",
        "        sr: int = TARGET_SR\n",
        "    ):\n",
        "        \"\"\"Save audio artifacts.\"\"\"\n",
        "        artifact_dir = ARTIFACTS_DIR / audio_name / f\"iter_{iteration}\"\n",
        "        artifact_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Save original\n",
        "        orig_path = artifact_dir / \"original.wav\"\n",
        "        sf.write(str(orig_path), original_audio, sr)\n",
        "        \n",
        "        # Save perturbed\n",
        "        pert_path = artifact_dir / f\"perturbed_{strategy_name}.wav\"\n",
        "        sf.write(str(pert_path), perturbed_audio, sr)\n",
        "        \n",
        "        print(f\"  Artifacts saved to: {artifact_dir}\")\n",
        "\n",
        "\n",
        "# Initialize main orchestrator\n",
        "orchestrator = AgentOrchestrator(\n",
        "    normalizer=normalizer,\n",
        "    asr_baseline=asr_baseline,\n",
        "    codec_detector=codec_detector,\n",
        "    codec_stack=codec_stack,\n",
        "    llm_orchestrator=llm_orchestrator,\n",
        "    perturbation_executor=perturbation_executor,\n",
        "    metrics_computer=metrics_computer\n",
        ")\n",
        "\n",
        "print(\"Main orchestrator initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Experiment\n",
        "\n",
        "Load a sample audio file and run the full pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Run experiment on a sample audio file\n",
        "# Replace with your audio file path\n",
        "sample_audio = Path(\"/Users/kunal/Downloads/adversarial_dataset-A/Adversarial-Examples/short-signals/Original-examples/sample-000303.wav\")\n",
        "\n",
        "if sample_audio.exists():\n",
        "    # Run experiment\n",
        "    results = orchestrator.run_experiment(\n",
        "        sample_audio,\n",
        "        reference_transcript=None,  # Will be auto-generated\n",
        "        max_iterations=MAX_ITERATIONS\n",
        "    )\n",
        "    \n",
        "    # Save results\n",
        "    results_path = RESULTS_DIR / f\"experiment_{sample_audio.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    orchestrator.save_results(results, results_path)\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"Experiment completed!\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "else:\n",
        "    print(f\"Audio file not found: {sample_audio}\")\n",
        "    print(\"Please update the sample_audio path above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Ablations and Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_ablations(results: List[ExperimentResult]) -> Dict[str, Any]:\n",
        "    \"\"\"Perform ablation studies on results.\"\"\"\n",
        "    ablations = {}\n",
        "    \n",
        "    # Convert to DataFrame for easier analysis\n",
        "    data = []\n",
        "    for result in results:\n",
        "        data.append({\n",
        "            \"iteration\": result.iteration,\n",
        "            \"strategy\": result.strategy_name,\n",
        "            \"wer_delta\": result.delta_metrics[\"wer_delta\"],\n",
        "            \"cer_delta\": result.delta_metrics[\"cer_delta\"],\n",
        "            \"pesq\": result.perturbed_metrics[\"pesq\"],\n",
        "            \"stoi\": result.perturbed_metrics[\"stoi\"],\n",
        "            \"snr\": result.perturbed_metrics[\"snr\"],\n",
        "            \"codec\": result.codec_info[\"codec_name\"]\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Ablation 1: With/without EoT\n",
        "    # (Compare direct perturbation vs EoT-averaged results)\n",
        "    if len(results) > 0:\n",
        "        direct_wer = df[\"wer_delta\"].mean()\n",
        "        eot_wer = np.mean([\n",
        "            np.mean([eot[\"wer_delta\"] for eot in r.eot_results])\n",
        "            for r in results if r.eot_results\n",
        "        ])\n",
        "        ablations[\"eot_impact\"] = {\n",
        "            \"direct_wer_delta\": direct_wer,\n",
        "            \"eot_wer_delta\": eot_wer,\n",
        "            \"improvement\": eot_wer - direct_wer\n",
        "        }\n",
        "    \n",
        "    # Ablation 2: Codec-specific performance\n",
        "    codec_performance = df.groupby(\"codec\").agg({\n",
        "        \"wer_delta\": [\"mean\", \"std\"],\n",
        "        \"pesq\": [\"mean\", \"std\"],\n",
        "        \"stoi\": [\"mean\", \"std\"]\n",
        "    }).to_dict()\n",
        "    ablations[\"codec_performance\"] = codec_performance\n",
        "    \n",
        "    # Ablation 3: Strategy family comparison\n",
        "    strategy_families = {}\n",
        "    for result in results:\n",
        "        family = result.strategy.get(\"family\", \"unknown\")\n",
        "        if family not in strategy_families:\n",
        "            strategy_families[family] = []\n",
        "        strategy_families[family].append(result.delta_metrics[\"wer_delta\"])\n",
        "    \n",
        "    ablations[\"strategy_families\"] = {\n",
        "        family: {\n",
        "            \"mean\": np.mean(deltas),\n",
        "            \"std\": np.std(deltas),\n",
        "            \"count\": len(deltas)\n",
        "        }\n",
        "        for family, deltas in strategy_families.items()\n",
        "    }\n",
        "    \n",
        "    # Statistical confidence intervals (bootstrap)\n",
        "    if len(df) > 0:\n",
        "        def bootstrap_mean(data, n_bootstrap=1000, confidence=0.95):\n",
        "            means = []\n",
        "            for _ in range(n_bootstrap):\n",
        "                sample = np.random.choice(data, size=len(data), replace=True)\n",
        "                means.append(np.mean(sample))\n",
        "            means = np.array(means)\n",
        "            lower = np.percentile(means, (1 - confidence) / 2 * 100)\n",
        "            upper = np.percentile(means, (1 - confidence) / 2 * 100 + confidence * 100)\n",
        "            return {\n",
        "                \"mean\": np.mean(means),\n",
        "                \"ci_lower\": lower,\n",
        "                \"ci_upper\": upper,\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "        \n",
        "        ablations[\"wer_delta_ci\"] = bootstrap_mean(df[\"wer_delta\"].values)\n",
        "        ablations[\"cer_delta_ci\"] = bootstrap_mean(df[\"cer_delta\"].values)\n",
        "    \n",
        "    return ablations\n",
        "\n",
        "\n",
        "def visualize_results(results: List[ExperimentResult], output_dir: Path):\n",
        "    \"\"\"Create visualizations of results.\"\"\"\n",
        "    if not results:\n",
        "        print(\"No results to visualize\")\n",
        "        return\n",
        "    \n",
        "    # Prepare data\n",
        "    data = []\n",
        "    for result in results:\n",
        "        data.append({\n",
        "            \"iteration\": result.iteration,\n",
        "            \"strategy\": result.strategy_name,\n",
        "            \"wer_delta\": result.delta_metrics[\"wer_delta\"],\n",
        "            \"cer_delta\": result.delta_metrics[\"cer_delta\"],\n",
        "            \"pesq\": result.perturbed_metrics[\"pesq\"],\n",
        "            \"stoi\": result.perturbed_metrics[\"stoi\"],\n",
        "            \"snr\": result.perturbed_metrics[\"snr\"]\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Create plots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # Plot 1: WER/CER delta over iterations\n",
        "    ax = axes[0, 0]\n",
        "    ax.plot(df[\"iteration\"], df[\"wer_delta\"], marker='o', label='WER Δ', linewidth=2)\n",
        "    ax.plot(df[\"iteration\"], df[\"cer_delta\"], marker='s', label='CER Δ', linewidth=2)\n",
        "    ax.set_xlabel(\"Iteration\")\n",
        "    ax.set_ylabel(\"Error Rate Delta\")\n",
        "    ax.set_title(\"ASR Performance Degradation Over Iterations\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Perceptual quality metrics\n",
        "    ax = axes[0, 1]\n",
        "    ax.plot(df[\"iteration\"], df[\"pesq\"], marker='o', label='PESQ', linewidth=2, color='green')\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(df[\"iteration\"], df[\"stoi\"], marker='s', label='STOI', linewidth=2, color='orange')\n",
        "    ax.set_xlabel(\"Iteration\")\n",
        "    ax.set_ylabel(\"PESQ\", color='green')\n",
        "    ax2.set_ylabel(\"STOI\", color='orange')\n",
        "    ax.set_title(\"Perceptual Quality Metrics\")\n",
        "    ax.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: SNR over iterations\n",
        "    ax = axes[1, 0]\n",
        "    ax.plot(df[\"iteration\"], df[\"snr\"], marker='o', linewidth=2, color='red')\n",
        "    ax.axhline(y=MIN_SNR, color='r', linestyle='--', label=f'Min SNR ({MIN_SNR} dB)')\n",
        "    ax.set_xlabel(\"Iteration\")\n",
        "    ax.set_ylabel(\"SNR (dB)\")\n",
        "    ax.set_title(\"Signal-to-Noise Ratio\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Strategy comparison\n",
        "    ax = axes[1, 1]\n",
        "    strategy_wer = df.groupby(\"strategy\")[\"wer_delta\"].mean().sort_values(ascending=False)\n",
        "    ax.barh(range(len(strategy_wer)), strategy_wer.values)\n",
        "    ax.set_yticks(range(len(strategy_wer)))\n",
        "    ax.set_yticklabels(strategy_wer.index)\n",
        "    ax.set_xlabel(\"Mean WER Delta\")\n",
        "    ax.set_title(\"Strategy Performance Comparison\")\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plot_path = output_dir / \"results_visualization.png\"\n",
        "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Visualization saved to: {plot_path}\")\n",
        "\n",
        "\n",
        "# Run ablations and visualization if results exist\n",
        "if 'results' in locals() and results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Performing Ablations and Statistical Analysis\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "    \n",
        "    ablations = perform_ablations(results)\n",
        "    \n",
        "    print(\"Ablation Results:\")\n",
        "    print(json.dumps(ablations, indent=2, default=str))\n",
        "    \n",
        "    # Save ablations\n",
        "    ablations_path = RESULTS_DIR / f\"ablations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(ablations_path, 'w') as f:\n",
        "        json.dump(ablations, f, indent=2, default=str)\n",
        "    print(f\"\\nAblations saved to: {ablations_path}\")\n",
        "    \n",
        "    # Create visualizations\n",
        "    visualize_results(results, RESULTS_DIR)\n",
        "else:\n",
        "    print(\"Run the experiment first to generate results for analysis.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
